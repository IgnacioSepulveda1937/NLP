{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114d9907-d621-4d95-8594-620cdb490ebc",
   "metadata": {},
   "source": [
    "# NLP 101\n",
    "\n",
    "minibootcamp dphi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd83c99-7b0b-44c1-a7a7-51f5d79145ac",
   "metadata": {},
   "source": [
    "Understand the interaction between computers and human language.\n",
    "\n",
    "Some applications are : \n",
    "\n",
    "* Information retrieval\n",
    "* Sentiment Ananlysis\n",
    "* Information Extration\n",
    "* Machine Traslation\n",
    "* Question Answering\n",
    "* Classification, Clustering and Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f646a39-7f9d-4bd1-81d7-71c6e2d8d2bd",
   "metadata": {},
   "source": [
    "<img src=\"Captura.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe2293-b777-4c24-b810-1c0260b0af68",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed93fe5-6a8b-4753-8a39-5b60dfc303db",
   "metadata": {},
   "source": [
    "<img src=\"Captura2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de28f27-8fad-4c7b-afa1-477de266bc78",
   "metadata": {},
   "source": [
    "### Case Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5703f3e6-cc48-4719-bfff-a32219e42fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Club deportivo Universidad Catolica'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='Club deportivo Universidad Catolica'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8dc22d1-ade4-4669-899c-0b1e7d3b5529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "club deportivo universidad catolica \n",
      "CLUB DEPORTIVO UNIVERSIDAD CATOLICA \n",
      " Club Deportivo Universidad Catolica\n"
     ]
    }
   ],
   "source": [
    "print(f'{text.lower()} \\n{text.upper()} \\n {text.title()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f997022-16b5-464e-a66f-403fd04ca26b",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfb41ea-da68-4cf4-86c8-791c48b659f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2526411-1615-4a85-ac95-eb4059e1d8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = (\"US unveils world's most powerful supercomputer, beats China. \" \n",
    "               \"The US has unveiled the world's most powerful supercomputer called 'Summit', \" \n",
    "               \"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n",
    "               \"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n",
    "               \"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n",
    "               \"which reportedly take up the size of two tennis courts.\")\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2793ce3b-3667-4ba8-a411-c25cc13a917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"US unveils world's most powerful supercomputer, beats China.\",\n",
       " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\",\n",
       " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.',\n",
       " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(sample_text) ## fila con comas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1e8eb2-59d2-4287-a6c9-cc6653ea53af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US', 'unveils', 'world', \"'s\", 'most', 'powerful', 'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has', 'unveiled', 'the', 'world', \"'s\", 'most', 'powerful', 'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the', 'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000', 'trillion', 'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size', 'of', 'two', 'tennis', 'courts', '.']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.word_tokenize(sample_text)) # Hace que cada set de string que no se encuentra separado por un espacio quede separado por ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb293f7c-6df7-47fd-a22d-335026fe5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy # Otra forma de hacer lo midsmo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592bd886-d396-4da9-8d04-fa14ed7e2055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"US unveils world's most powerful supercomputer, beats China.\",\n",
       " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\",\n",
       " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.',\n",
       " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "text_spacy = nlp(sample_text)\n",
    "## sentenciaa\n",
    "[obj.text for obj in text_spacy.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28401be4-2fa2-4348-8801-d5b7b0a9f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US', 'unveils', 'world', \"'s\", 'most', 'powerful', 'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has', 'unveiled', 'the', 'world', \"'s\", 'most', 'powerful', 'supercomputer', 'called', \"'\", 'Summit', \"'\", ',', 'beating', 'the', 'previous', 'record', '-', 'holder', 'China', \"'s\", 'Sunway', 'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000', 'trillion', 'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size', 'of', 'two', 'tennis', 'courts', '.']\n"
     ]
    }
   ],
   "source": [
    "## tokenizate\n",
    "print([obj.text for obj in text_spacy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d907e-1e0b-4c4f-a5ee-4080388ae9e7",
   "metadata": {},
   "source": [
    "### Removing HTML tags and Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeced7a6-7363-4d0e-ae51-d57017afccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgin-top: 2em\">*** START OF THE PROJECT GUTENBERG EBOOK, THE BIBLE, KING JAMES, BOOK 1***</p>\n",
      "\n",
      "<p id=\"id00012\" style=\"margin-top: 4em\">This eBook was produced by David Widger\n",
      "with the help of Derek Andrew's text from January 1992\n",
      "and the work of Bryan Taylor in November 2002.</p>\n",
      "\n",
      "<h1 id=\"id00013\" style=\"margin-top: 5em\">Book 01        Genesis</h1>\n",
      "\n",
      "<p id=\"id00014\">01:001:001 In the beginning God created the heaven and the earth.</p>\n",
      "\n",
      "<p id=\"id00015\" style=\"margin-left: 0%; margin-right: 0%\">01:001:002 And the earth was without form, and void; and darkness was\n",
      "           upon the face of the deep. And the Spirit of God moved upon\n",
      "           the face of the waters.</p>\n",
      "\n",
      "<p id=\"id00016\">01:001:003 And God said, Let there be light: and there was light.</p>\n",
      "\n",
      "<p id=\"id00017\">01:001:004 And God saw the light, that it was good: and God divided the<br>\n",
      "\n",
      "           light from the darkness.<br>\n",
      "</p>\n",
      "\n",
      "<p id=\"id00018\">01:001:005 And God called the light Day, and the darkness he called<br>\n",
      "\n",
      "           Night. And the evening and the morning were the first day.<br>\n",
      "</p>\n",
      "\n",
      "<p id=\"id00019\">01:001:006 And God said, Let there be a firmament in the midst of the<br>\n",
      "\n",
      "           waters, and let it divide the waters from the waters.<br>\n",
      "</p>\n",
      "\n",
      "<p id=\"id00020\" style=\"margin-left: 0%; margin-right: 0%\">01:001:007 And God made the firmament, and divided the waters which were\n",
      "           under the firmament from the waters which were above the\n",
      "           firmament: and it was so.</p>\n",
      "\n",
      "<p id=\"id00021\" style=\"margin-left: 0%; margin-right: 0%\">01:001:008 And God called the firmament Heaven. And the evening and the\n",
      "           morning were the second day.</p>\n",
      "\n",
      "<p id=\"id00022\" style=\"margin-left: 0%; margin-right: 0%\">01:001:009 And God said, Let the waters under the heaven be gathered\n",
      "           together unto one place, and let the dry land appear: and it\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get('http://www.gutenberg.org/cache/epub/8001/pg8001.html')\n",
    "content = data.text\n",
    "print(content[6100:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7665aa3-89a4-411d-afb5-6bc0121c7feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f the earth, and to every fowl of the air,\n",
      "           and to every thing that creepeth upon the earth, wherein there\n",
      "           is life, I have given every green herb for meat: and it was\n",
      "           so.\n",
      "01:001:031 And God saw every thing that he had made, and, behold, it was\n",
      "           very good. And the evening and the morning were the sixth day.\n",
      "01:002:001 Thus the heavens and the earth were finished, and all the host\n",
      "           of them.\n",
      "01:002:002 And on the seventh day God ended his work which he had made;\n",
      "           and he rested on the seventh day from all his work which he\n",
      "           had made.\n",
      "01:002:003 And God blessed the seventh day, and sanctified it: because\n",
      "           that in it he had rested from all his work which God created\n",
      "           and made.\n",
      "01:002:004 These are the generations of the heavens and of the earth when\n",
      "           they were created, in the day that the LORD God made the earth\n",
      "           and the heavens,\n",
      "01:002:005 And every plant of the field before it was in the earth, and\n",
      "           every herb of the field before it grew: for the LORD God had\n",
      "           not caused it to rain upon the earth, and there was not a man\n",
      "           to till the ground.\n",
      "01:002:006 But there went up a mist from the earth, and watered the whole\n",
      "           face of the ground.\n",
      "01:002:007 And the LORD God formed man of the dust of the ground, and\n",
      "           breathed into his nostrils the breath of life; and man became\n",
      "           a living soul.\n",
      "01:002:008 And the LORD God planted a garden eastward in Eden; and there\n",
      "           he put the man whom he had formed.\n",
      "01:002:009 And out of the ground made the LORD God to grow every tree\n",
      "           that is pleasant to the sight, and good for food; the tree of\n",
      "           life also in the midst of the garden, and the tree of\n",
      "           knowledge of good and evil.\n",
      "01:002:010 And a river went out of Eden to water the garden; and\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "clean_content = strip_html_tags(content)\n",
    "print(clean_content[6100:8000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099d5ef-37bb-43f4-93bd-f602509182e7",
   "metadata": {},
   "source": [
    "### Removing Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b03ee71-1353-4449-a454-94e5698a1776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0e9f14-b1dc-4caa-b108-957514c230ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('únívérsídád cátólícá', 'universidad catolica')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto='únívérsídád cátólícá'\n",
    "texto,remove_accented_chars(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d15fc-0c35-487f-b968-d438f9cb6bd2",
   "metadata": {},
   "source": [
    "### Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a037944-242f-4270-a3a6-05a3c5ec95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "520de247-ff78-46a9-ae9a-3acd557169bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Club Deportivo Universidad Catolica #1 !!!!!!! 🙂🙂🙂\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df844be4-5c45-4b63-9ea7-d730ac568377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Club Deportivo Universidad Catolica 1  '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_characters(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a97698-e066-4489-bceb-582ec406806c",
   "metadata": {},
   "source": [
    "### Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1781e2fa-f289-4532-881a-60eeb99d5367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\ignacio.sepulveda\\anaconda3\\lib\\site-packages (0.1.66)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\ignacio.sepulveda\\anaconda3\\lib\\site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: anyascii in c:\\users\\ignacio.sepulveda\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\ignacio.sepulveda\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
      "Requirement already satisfied: textsearch in c:\\users\\ignacio.sepulveda\\anaconda3\\lib\\site-packages (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\ignacio.sepulveda\\anaconda3\\lib\\site-packages (from textsearch) (1.4.2)\n",
      "Requirement already satisfied: anyascii in c:\\users\\ignacio.sepulveda\\anaconda3\\lib\\site-packages (from textsearch) (0.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "589ea743-1abc-4bf3-ba33-3c89f25be8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"I'm\", 'I am'),\n",
       " (\"I'm'a\", 'I am about to'),\n",
       " (\"I'm'o\", 'I am going to'),\n",
       " (\"I've\", 'I have'),\n",
       " (\"I'll\", 'I will'),\n",
       " (\"I'll've\", 'I will have'),\n",
       " (\"I'd\", 'I would'),\n",
       " (\"I'd've\", 'I would have'),\n",
       " ('Whatcha', 'What are you'),\n",
       " (\"amn't\", 'am not')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "list(contractions.contractions_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d08ad72-efeb-4344-bb90-da4f280ed0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto='''They aren't playing football cause They doesn't have ball'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68c968fa-0fed-459f-8537-a85febe6af58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They are not playing football because They does not have ball'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions.fix(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6704c-3420-4424-8201-ebd00608e468",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "426580a0-f95b-42ea-9f7d-220e03761515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8385cf-5f2a-4e23-92d3-2090d56d9505",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd672aa8-0207-4a2b-9932-b6085ad5f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b9c2b22-567e-4c8d-8bb2-0232be250e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook\n",
      "box\n"
     ]
    }
   ],
   "source": [
    "# lemmatize nouns\n",
    "print(wnl.lemmatize('notebooks', 'n'))\n",
    "print(wnl.lemmatize('boxes', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e6893e4-83cd-4f07-adc0-b7bfdab26a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# lemmatize verbs\n",
    "print(wnl.lemmatize('ran', 'v'))\n",
    "print(wnl.lemmatize('ate', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeb82d35-7144-4eab-9b6f-76628af23a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poor\n",
      "ugly\n"
     ]
    }
   ],
   "source": [
    "# lemmatize adjectives\n",
    "print(wnl.lemmatize('poorest', 'a'))\n",
    "print(wnl.lemmatize('ugliest', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c97d012-010a-41c1-97f3-c70932fa5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ba39cde-5ed9-4cc9-87e7-7f45fc463fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brown fox are quick and they are jumping over the sleeping lazy dog !'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(s)\n",
    "lemmatized_text = ' '.join(wnl.lemmatize(token) for token in tokens)\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeeecb80-3ab2-4220-a5e7-8594bea2f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pos Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23edd8c5-c664-435a-9de4-142d2ea8d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "print(tagged_tokens)\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def pos_tag_wordnet(tagged_tokens):\n",
    "    tag_map = {'j': wordnet.ADJ, 'v': wordnet.VERB, 'n': wordnet.NOUN, 'r': wordnet.ADV}\n",
    "    new_tagged_tokens = [(word, tag_map.get(tag[0].lower(), wordnet.NOUN))\n",
    "                            for word, tag in tagged_tokens]\n",
    "    return new_tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efe6c297-c415-4f5a-bb41-74c823d5ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'n'), ('brown', 'a'), ('foxes', 'n'), ('are', 'v'), ('quick', 'a'), ('and', 'n'), ('they', 'n'), ('are', 'v'), ('jumping', 'v'), ('over', 'n'), ('the', 'n'), ('sleeping', 'v'), ('lazy', 'a'), ('dogs', 'n'), ('!', 'n')]\n"
     ]
    }
   ],
   "source": [
    "wordnet_tokens = pos_tag_wordnet(tagged_tokens)\n",
    "print(wordnet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c8e1e5-3a3c-4f96-8d95-191c70de8887",
   "metadata": {},
   "source": [
    "### Effective Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95b288f5-3a86-4c69-a299-3dc02d966fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brown fox be quick and they be jump over the sleep lazy dog !'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text = ' '.join(wnl.lemmatize(word, tag) for word, tag in wordnet_tokens)\n",
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea9546-44a6-4c7f-ba56-99482d382299",
   "metadata": {},
   "source": [
    "### Lemmatization with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39c921f2-5c12-4907-bfd1-e85fd4bfa644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def spacy_lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c26bbbf2-99f0-45e7-aa4f-a8da194b5ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the brown fox be quick and they be jump over the sleep lazy dog !'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_lemmatize_text(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98566c0-2397-4b89-9fe0-d1723ef6892e",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7299fc45-5cf1-432c-9a43-720089bb2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False, stopwords=None):\n",
    "    if not stopwords:\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    \n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    \n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9268240-856c-4195-91da-342a70aad253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44fc6339-1a28-4baf-bf59-90d465982e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brown foxes quick jumping sleeping lazy dogs !'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(s, is_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24020de9-9fc0-4579-9435-7c48c54bb440",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text Representation with Feature Engineering\n",
    "\n",
    "Bootcamp NLP -dphi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262c8d7-2e38-4c2e-9490-bb3d15749bf1",
   "metadata": {},
   "source": [
    "How I do the engineering for transform free text in numeric features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af2a2b-c041-43ef-92c5-8244dff3c8ce",
   "metadata": {},
   "source": [
    "### Sample Corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271a25c-9638-4408-a572-40e7a0d19a8c",
   "metadata": {},
   "source": [
    "Es la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3f49881-79a4-4096-95ca-03ba32b7888f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document Category\n",
       "0                                      The sky is blue and beautiful.  weather\n",
       "1                                   Love this blue and beautiful sky!  weather\n",
       "2                        The quick brown fox jumps over the lazy dog.  animals\n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
       "4                         I love green eggs, ham, sausages and bacon!     food\n",
       "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
       "6            The sky is very blue and the sky is very beautiful today  weather\n",
       "7                         The dog is lazy but the brown fox is quick!  animals"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!'    \n",
    "]\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
    "\n",
    "corpus = np.array(corpus)\n",
    "corpus_df = pd.DataFrame({'Document': corpus, \n",
    "                          'Category': labels})\n",
    "corpus_df = corpus_df[['Document', 'Category']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1002fa56-7598-49ef-a562-6ed672ab5b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sky blue beautiful', 'love blue beautiful sky',\n",
       "       'quick brown fox jumps lazy dog',\n",
       "       'kings breakfast sausages ham bacon eggs toast beans',\n",
       "       'love green eggs ham sausages bacon',\n",
       "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
       "       'dog lazy brown fox quick'], dtype='<U51')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Pre-procesing\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A) ## caracteres especiales\n",
    "    doc = doc.lower() ## Todo a minuscula\n",
    "    doc = doc.strip() ## Eliminas espacios\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc) \n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words] ## Saca los y,o, en etc\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(corpus)\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f39fe-b08d-434a-a4d3-52bbae32d7cc",
   "metadata": {},
   "source": [
    "### Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ae177cc-4d15-43e2-bef5-ecaae4220dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(norm_corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99bb5c0e-611f-4038-9a17-21bfc1ef4f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacon</th>\n",
       "      <th>beans</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>eggs</th>\n",
       "      <th>fox</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>jumps</th>\n",
       "      <th>kings</th>\n",
       "      <th>lazy</th>\n",
       "      <th>love</th>\n",
       "      <th>quick</th>\n",
       "      <th>sausages</th>\n",
       "      <th>sky</th>\n",
       "      <th>toast</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bacon  beans  beautiful  blue  breakfast  brown  dog  eggs  fox  green  \\\n",
       "0      0      0          1     1          0      0    0     0    0      0   \n",
       "1      0      0          1     1          0      0    0     0    0      0   \n",
       "2      0      0          0     0          0      1    1     0    1      0   \n",
       "3      1      1          0     0          1      0    0     1    0      0   \n",
       "4      1      0          0     0          0      0    0     1    0      1   \n",
       "5      0      0          0     1          0      1    1     0    1      0   \n",
       "6      0      0          1     1          0      0    0     0    0      0   \n",
       "7      0      0          0     0          0      1    1     0    1      0   \n",
       "\n",
       "   ham  jumps  kings  lazy  love  quick  sausages  sky  toast  today  \n",
       "0    0      0      0     0     0      0         0    1      0      0  \n",
       "1    0      0      0     0     1      0         0    1      0      0  \n",
       "2    0      1      0     1     0      1         0    0      0      0  \n",
       "3    1      0      1     0     0      0         1    0      1      0  \n",
       "4    1      0      0     0     1      0         1    0      0      0  \n",
       "5    0      0      0     1     0      1         0    0      0      0  \n",
       "6    0      0      0     0     0      0         0    2      0      1  \n",
       "7    0      0      0     1     0      1         0    0      0      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names()\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)\n",
    "\n",
    "### La matriz esta ordenada por abcdario y pero las filas estan ordenadas, cada fila es un elemento del vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a6ad4-f4fd-4766-8a15-6df43c7f5754",
   "metadata": {},
   "source": [
    "### Bag of N-Grams Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d00a1c-4257-4997-912f-28ea462c08de",
   "metadata": {},
   "source": [
    "Lo mismo pero ahora mezcla n secuencia de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eacda6c0-3a2d-41ec-87cc-309c0697aa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacon eggs</th>\n",
       "      <th>beautiful sky</th>\n",
       "      <th>beautiful today</th>\n",
       "      <th>blue beautiful</th>\n",
       "      <th>blue dog</th>\n",
       "      <th>blue sky</th>\n",
       "      <th>breakfast sausages</th>\n",
       "      <th>brown fox</th>\n",
       "      <th>dog lazy</th>\n",
       "      <th>eggs ham</th>\n",
       "      <th>...</th>\n",
       "      <th>lazy dog</th>\n",
       "      <th>love blue</th>\n",
       "      <th>love green</th>\n",
       "      <th>quick blue</th>\n",
       "      <th>quick brown</th>\n",
       "      <th>sausages bacon</th>\n",
       "      <th>sausages ham</th>\n",
       "      <th>sky beautiful</th>\n",
       "      <th>sky blue</th>\n",
       "      <th>toast beans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bacon eggs  beautiful sky  beautiful today  blue beautiful  blue dog  \\\n",
       "0           0              0                0               1         0   \n",
       "1           0              1                0               1         0   \n",
       "2           0              0                0               0         0   \n",
       "3           1              0                0               0         0   \n",
       "4           0              0                0               0         0   \n",
       "5           0              0                0               0         1   \n",
       "6           0              0                1               0         0   \n",
       "7           0              0                0               0         0   \n",
       "\n",
       "   blue sky  breakfast sausages  brown fox  dog lazy  eggs ham  ...  lazy dog  \\\n",
       "0         0                   0          0         0         0  ...         0   \n",
       "1         0                   0          0         0         0  ...         0   \n",
       "2         0                   0          1         0         0  ...         1   \n",
       "3         0                   1          0         0         0  ...         0   \n",
       "4         0                   0          0         0         1  ...         0   \n",
       "5         0                   0          1         1         0  ...         0   \n",
       "6         1                   0          0         0         0  ...         0   \n",
       "7         0                   0          1         1         0  ...         0   \n",
       "\n",
       "   love blue  love green  quick blue  quick brown  sausages bacon  \\\n",
       "0          0           0           0            0               0   \n",
       "1          1           0           0            0               0   \n",
       "2          0           0           0            1               0   \n",
       "3          0           0           0            0               0   \n",
       "4          0           1           0            0               1   \n",
       "5          0           0           1            0               0   \n",
       "6          0           0           0            0               0   \n",
       "7          0           0           0            0               0   \n",
       "\n",
       "   sausages ham  sky beautiful  sky blue  toast beans  \n",
       "0             0              0         1            0  \n",
       "1             0              0         0            0  \n",
       "2             0              0         0            0  \n",
       "3             1              0         0            1  \n",
       "4             0              0         0            0  \n",
       "5             0              0         0            0  \n",
       "6             0              1         1            0  \n",
       "7             0              0         0            0  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab = bv.get_feature_names()\n",
    "pd.DataFrame(bv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb53cbde-d285-4957-9653-ebffe961d975",
   "metadata": {},
   "source": [
    "### TF-IDF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4e3350-e5c9-40d2-b984-0d087ebcc1a6",
   "metadata": {},
   "source": [
    "El problema de los bags es que se basan en frecuencia absoluta entonces para una corpora en particular pueden haber tokens que hagan que el efecto relativo de las otras palabras sea menor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c3b71-6b1e-46ac-9d4b-0cb5851e4445",
   "metadata": {},
   "source": [
    "Term Frequency-Inverse Document Frequency usa un factor de normalizacion para tratar con esto "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ba358-a399-443d-8ac9-a01ecfb66db0",
   "metadata": {},
   "source": [
    "$\\text{tfidf}(w,D)=\\text{tf}(w,D)\\text{idf}(w,D)$\n",
    "\n",
    ",donde tf es la frecuencia de la palabra w en el documento D y idf la inversa de la frecuencia del documento que la define como el log del total de Documentos($D$) en el Corpus($C$) dividido por la cantidad de documentos que contienen la palabra w. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66c73743-59dd-415c-8473-cfd073700ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacon</th>\n",
       "      <th>beans</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>eggs</th>\n",
       "      <th>fox</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>jumps</th>\n",
       "      <th>kings</th>\n",
       "      <th>lazy</th>\n",
       "      <th>love</th>\n",
       "      <th>quick</th>\n",
       "      <th>sausages</th>\n",
       "      <th>sky</th>\n",
       "      <th>toast</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bacon  beans  beautiful  blue  breakfast  brown   dog  eggs   fox  green  \\\n",
       "0   0.00   0.00       0.60  0.53       0.00   0.00  0.00  0.00  0.00   0.00   \n",
       "1   0.00   0.00       0.49  0.43       0.00   0.00  0.00  0.00  0.00   0.00   \n",
       "2   0.00   0.00       0.00  0.00       0.00   0.38  0.38  0.00  0.38   0.00   \n",
       "3   0.32   0.38       0.00  0.00       0.38   0.00  0.00  0.32  0.00   0.00   \n",
       "4   0.39   0.00       0.00  0.00       0.00   0.00  0.00  0.39  0.00   0.47   \n",
       "5   0.00   0.00       0.00  0.37       0.00   0.42  0.42  0.00  0.42   0.00   \n",
       "6   0.00   0.00       0.36  0.32       0.00   0.00  0.00  0.00  0.00   0.00   \n",
       "7   0.00   0.00       0.00  0.00       0.00   0.45  0.45  0.00  0.45   0.00   \n",
       "\n",
       "    ham  jumps  kings  lazy  love  quick  sausages   sky  toast  today  \n",
       "0  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.60   0.00    0.0  \n",
       "1  0.00   0.00   0.00  0.00  0.57   0.00      0.00  0.49   0.00    0.0  \n",
       "2  0.00   0.53   0.00  0.38  0.00   0.38      0.00  0.00   0.00    0.0  \n",
       "3  0.32   0.00   0.38  0.00  0.00   0.00      0.32  0.00   0.38    0.0  \n",
       "4  0.39   0.00   0.00  0.00  0.39   0.00      0.39  0.00   0.00    0.0  \n",
       "5  0.00   0.00   0.00  0.42  0.00   0.42      0.00  0.00   0.00    0.0  \n",
       "6  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.72   0.00    0.5  \n",
       "7  0.00   0.00   0.00  0.45  0.00   0.45      0.00  0.00   0.00    0.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25651bee-7377-48f5-bb2d-92d33e84c945",
   "metadata": {},
   "source": [
    "### Document Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751abcbc-a979-4df8-943e-0826097d1901",
   "metadata": {},
   "source": [
    "Entrega una matriz como de cuan parecidos son casa frase o document, classic nxn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec2fed4b-a22b-459a-ab1c-5d44fcba4210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192353</td>\n",
       "      <td>0.817246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225489</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.670631</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.192353</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.791821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115488</td>\n",
       "      <td>0.930989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.817246</td>\n",
       "      <td>0.670631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.820599  0.000000  0.000000  0.000000  0.192353  0.817246   \n",
       "1  0.820599  1.000000  0.000000  0.000000  0.225489  0.157845  0.670631   \n",
       "2  0.000000  0.000000  1.000000  0.000000  0.000000  0.791821  0.000000   \n",
       "3  0.000000  0.000000  0.000000  1.000000  0.506866  0.000000  0.000000   \n",
       "4  0.000000  0.225489  0.000000  0.506866  1.000000  0.000000  0.000000   \n",
       "5  0.192353  0.157845  0.791821  0.000000  0.000000  1.000000  0.115488   \n",
       "6  0.817246  0.670631  0.000000  0.000000  0.000000  0.115488  1.000000   \n",
       "7  0.000000  0.000000  0.850516  0.000000  0.000000  0.930989  0.000000   \n",
       "\n",
       "          7  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.850516  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.930989  \n",
       "6  0.000000  \n",
       "7  1.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f43fe-9556-4c0d-9513-b836713cc1dd",
   "metadata": {},
   "source": [
    "### Ex Clustering with Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6007ac77-7521-4578-ba60-808b5a7432a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document  \\\n",
       "0                                      The sky is blue and beautiful.   \n",
       "1                                   Love this blue and beautiful sky!   \n",
       "2                        The quick brown fox jumps over the lazy dog.   \n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans   \n",
       "4                         I love green eggs, ham, sausages and bacon!   \n",
       "5                    The brown fox is quick and the blue dog is lazy!   \n",
       "6            The sky is very blue and the sky is very beautiful today   \n",
       "7                         The dog is lazy but the brown fox is quick!   \n",
       "\n",
       "  Category  ClusterLabel  \n",
       "0  weather             2  \n",
       "1  weather             2  \n",
       "2  animals             1  \n",
       "3     food             0  \n",
       "4     food             0  \n",
       "5  animals             1  \n",
       "6  weather             2  \n",
       "7  animals             1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=3, random_state=0)\n",
    "km.fit_transform(similarity_matrix)\n",
    "cluster_labels = km.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
    "pd.concat([corpus_df, cluster_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb91a16-5c68-4038-b9f3-f55debc4c92f",
   "metadata": {},
   "source": [
    "## Text Representacion with New Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afded134-bc0d-4d0a-958c-fcf187a8b669",
   "metadata": {},
   "source": [
    "La idea es explorar formas mas sofisticas que no se basen en solo metricas de conteo, si no que tambien capturen la semantica. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e84585-58d4-4538-b04c-bec2bec2790b",
   "metadata": {},
   "source": [
    "### Sample Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81693c87-05d1-4a1a-8936-b7f1037674d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document Category\n",
       "0                                      The sky is blue and beautiful.  weather\n",
       "1                                   Love this blue and beautiful sky!  weather\n",
       "2                        The quick brown fox jumps over the lazy dog.  animals\n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
       "4                         I love green eggs, ham, sausages and bacon!     food\n",
       "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
       "6            The sky is very blue and the sky is very beautiful today  weather\n",
       "7                         The dog is lazy but the brown fox is quick!  animals"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!'    \n",
    "]\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
    "\n",
    "corpus = np.array(corpus)\n",
    "corpus_df = pd.DataFrame({'Document': corpus, \n",
    "                          'Category': labels})\n",
    "corpus_df = corpus_df[['Document', 'Category']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda2774-290b-4e2a-98b8-59ec875ae89d",
   "metadata": {},
   "source": [
    "### Simple pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cbb13f8-ccb8-4b21-b54c-5a313b2f6cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sky blue beautiful', 'love blue beautiful sky',\n",
       "       'quick brown fox jumps lazy dog',\n",
       "       'kings breakfast sausages ham bacon eggs toast beans',\n",
       "       'love green eggs ham sausages bacon',\n",
       "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
       "       'dog lazy brown fox quick'], dtype='<U51')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(corpus)\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f8b4c-8674-448b-b0b6-e30d6543e5ca",
   "metadata": {},
   "source": [
    "### The Word2Vec Model\n",
    "\n",
    "* Google 2013\n",
    "\n",
    "* Menor dimencionalidad y mayor densidad en la matriz comparado a metodos tradicionales de Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff6c0e-1ad0-4391-a1b6-5ba3d9596b86",
   "metadata": {},
   "source": [
    "Use two types of Architectures:\n",
    "    \n",
    "   * The continuous Bag of Words (CBOW) Model.\n",
    "   \n",
    "   Este se trata de intentar predecir la palabra que se encuentra al medio en funcion de las que la rodean.  Por ejemplo: 'Un auto familiar gris choca con un auto rojo deportivo'.\n",
    "   \n",
    "   Entonces, por ejemplo:\n",
    "   \n",
    "   $x=(auto,gris)\\:\\rightarrow f(x)=familiar$\n",
    "   $x=(auto,deportivo)\\:\\rightarrow f(x)=rojo$\n",
    "\n",
    "   \n",
    "   A x se le llama el context window y a f(x) el target word. \n",
    "   \n",
    "   * The Skip-gram Model. \n",
    "    \n",
    "   Hace lo del CBOW pero al reves, esto implica\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9b49d-4748-4236-9f85-c313717061c2",
   "metadata": {},
   "source": [
    "#### Robust Word2Vec Model with Gensim\n",
    "\n",
    "Ocupa estos parametros :\n",
    "\n",
    "* size: The word embedding dimensionality\n",
    "* window: The context window size\n",
    "* min_count: The minimum word count\n",
    "* sample: The downsample setting for frequent words\n",
    "* sg: Training model, 1 for skip-gram otherwise CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40ea4952-35ee-495f-8cf2-5b3ffa95efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38e7455d-6be6-44fe-b881-3d105c2a1128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x2381213c550>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in norm_corpus]\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 15    # Word vector dimensionality  \n",
    "window_context = 20  # Context window size                                                                                    \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "sample = 1e-3        # Downsample setting for frequent words\n",
    "sg = 1               # skip-gram model\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus, vector_size=feature_size, \n",
    "                              window=window_context, min_count = min_word_count,\n",
    "                              sg=sg, sample=sample,epochs=5000)\n",
    "w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "238182c1-6a30-431d-9fe3-de03a24119d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# visualize embeddings\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "words = w2v_model.wv.index_to_key\n",
    "wvs = w2v_model.wv[words]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, n_iter=5000, perplexity=5)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(wvs)\n",
    "labels = words\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='orange', edgecolors='r')\n",
    "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc429a19-817e-4cb3-ac75-16037cef8ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sky</th>\n",
       "      <td>-0.639432</td>\n",
       "      <td>-0.024679</td>\n",
       "      <td>1.502709</td>\n",
       "      <td>0.610270</td>\n",
       "      <td>-0.721669</td>\n",
       "      <td>-0.316005</td>\n",
       "      <td>0.965002</td>\n",
       "      <td>1.001847</td>\n",
       "      <td>-0.234204</td>\n",
       "      <td>0.705497</td>\n",
       "      <td>0.514538</td>\n",
       "      <td>0.877368</td>\n",
       "      <td>-0.751616</td>\n",
       "      <td>-0.470609</td>\n",
       "      <td>0.071282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>-0.602743</td>\n",
       "      <td>0.073659</td>\n",
       "      <td>0.724945</td>\n",
       "      <td>0.157942</td>\n",
       "      <td>-0.789465</td>\n",
       "      <td>0.215237</td>\n",
       "      <td>0.614432</td>\n",
       "      <td>0.679531</td>\n",
       "      <td>-0.048113</td>\n",
       "      <td>0.658686</td>\n",
       "      <td>0.095931</td>\n",
       "      <td>0.815805</td>\n",
       "      <td>-0.159200</td>\n",
       "      <td>-0.532422</td>\n",
       "      <td>-0.248695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>-0.988989</td>\n",
       "      <td>0.319340</td>\n",
       "      <td>0.843687</td>\n",
       "      <td>-1.026609</td>\n",
       "      <td>-0.590684</td>\n",
       "      <td>0.173463</td>\n",
       "      <td>0.259514</td>\n",
       "      <td>-0.637999</td>\n",
       "      <td>0.504987</td>\n",
       "      <td>0.112339</td>\n",
       "      <td>-0.474345</td>\n",
       "      <td>1.303706</td>\n",
       "      <td>-0.684338</td>\n",
       "      <td>-1.083380</td>\n",
       "      <td>0.311884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>-0.544188</td>\n",
       "      <td>-0.353933</td>\n",
       "      <td>1.410363</td>\n",
       "      <td>0.720159</td>\n",
       "      <td>-0.013280</td>\n",
       "      <td>-0.414286</td>\n",
       "      <td>0.896078</td>\n",
       "      <td>0.552768</td>\n",
       "      <td>-0.145792</td>\n",
       "      <td>1.038409</td>\n",
       "      <td>0.312691</td>\n",
       "      <td>0.896521</td>\n",
       "      <td>-0.635649</td>\n",
       "      <td>-0.480671</td>\n",
       "      <td>0.334769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick</th>\n",
       "      <td>-0.789416</td>\n",
       "      <td>0.323791</td>\n",
       "      <td>0.290438</td>\n",
       "      <td>-0.849889</td>\n",
       "      <td>-0.650918</td>\n",
       "      <td>0.278436</td>\n",
       "      <td>-0.141102</td>\n",
       "      <td>-0.187405</td>\n",
       "      <td>0.451341</td>\n",
       "      <td>0.482975</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>1.579678</td>\n",
       "      <td>-0.351136</td>\n",
       "      <td>-1.142641</td>\n",
       "      <td>0.484352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>-0.712770</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.521078</td>\n",
       "      <td>-0.705848</td>\n",
       "      <td>-1.008142</td>\n",
       "      <td>0.141744</td>\n",
       "      <td>0.080199</td>\n",
       "      <td>-0.064908</td>\n",
       "      <td>0.848459</td>\n",
       "      <td>-0.062610</td>\n",
       "      <td>-0.022713</td>\n",
       "      <td>1.501421</td>\n",
       "      <td>-0.514936</td>\n",
       "      <td>-0.974268</td>\n",
       "      <td>0.667429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>-0.896241</td>\n",
       "      <td>0.404933</td>\n",
       "      <td>0.753256</td>\n",
       "      <td>-0.695366</td>\n",
       "      <td>-0.435905</td>\n",
       "      <td>0.327127</td>\n",
       "      <td>-0.346009</td>\n",
       "      <td>-0.465849</td>\n",
       "      <td>0.637149</td>\n",
       "      <td>0.599076</td>\n",
       "      <td>-0.256180</td>\n",
       "      <td>1.590770</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>-0.898548</td>\n",
       "      <td>0.597680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>-0.949771</td>\n",
       "      <td>0.453110</td>\n",
       "      <td>0.776009</td>\n",
       "      <td>-0.624677</td>\n",
       "      <td>-0.637290</td>\n",
       "      <td>0.142310</td>\n",
       "      <td>-0.439198</td>\n",
       "      <td>-0.422219</td>\n",
       "      <td>0.756097</td>\n",
       "      <td>0.316867</td>\n",
       "      <td>0.205115</td>\n",
       "      <td>1.447336</td>\n",
       "      <td>-0.020938</td>\n",
       "      <td>-0.981581</td>\n",
       "      <td>0.459399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sausages</th>\n",
       "      <td>0.198648</td>\n",
       "      <td>0.176316</td>\n",
       "      <td>1.074163</td>\n",
       "      <td>-0.299473</td>\n",
       "      <td>1.010429</td>\n",
       "      <td>0.748644</td>\n",
       "      <td>-0.166153</td>\n",
       "      <td>0.556175</td>\n",
       "      <td>-0.244341</td>\n",
       "      <td>0.325445</td>\n",
       "      <td>0.850126</td>\n",
       "      <td>-0.310548</td>\n",
       "      <td>-0.408820</td>\n",
       "      <td>-0.935457</td>\n",
       "      <td>0.673599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0.297497</td>\n",
       "      <td>0.631223</td>\n",
       "      <td>1.108528</td>\n",
       "      <td>0.457518</td>\n",
       "      <td>1.037477</td>\n",
       "      <td>1.027660</td>\n",
       "      <td>-0.164433</td>\n",
       "      <td>0.289555</td>\n",
       "      <td>-0.268838</td>\n",
       "      <td>-0.167446</td>\n",
       "      <td>0.689474</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>-0.524910</td>\n",
       "      <td>-0.758180</td>\n",
       "      <td>0.730475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>0.566377</td>\n",
       "      <td>0.017698</td>\n",
       "      <td>0.900351</td>\n",
       "      <td>0.066918</td>\n",
       "      <td>0.828408</td>\n",
       "      <td>1.132224</td>\n",
       "      <td>0.374976</td>\n",
       "      <td>0.695544</td>\n",
       "      <td>-0.307900</td>\n",
       "      <td>0.289053</td>\n",
       "      <td>0.316389</td>\n",
       "      <td>-0.160405</td>\n",
       "      <td>-0.618389</td>\n",
       "      <td>-1.018001</td>\n",
       "      <td>0.789529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0.123760</td>\n",
       "      <td>0.780017</td>\n",
       "      <td>0.875009</td>\n",
       "      <td>0.150625</td>\n",
       "      <td>0.959082</td>\n",
       "      <td>0.564490</td>\n",
       "      <td>-0.189527</td>\n",
       "      <td>0.971184</td>\n",
       "      <td>-0.022017</td>\n",
       "      <td>-0.024021</td>\n",
       "      <td>0.362688</td>\n",
       "      <td>-0.340379</td>\n",
       "      <td>-0.629636</td>\n",
       "      <td>-1.026932</td>\n",
       "      <td>0.675302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>-0.394468</td>\n",
       "      <td>0.130106</td>\n",
       "      <td>0.939160</td>\n",
       "      <td>0.273528</td>\n",
       "      <td>0.538580</td>\n",
       "      <td>-0.035836</td>\n",
       "      <td>0.319965</td>\n",
       "      <td>0.581181</td>\n",
       "      <td>-0.265422</td>\n",
       "      <td>0.164804</td>\n",
       "      <td>0.601005</td>\n",
       "      <td>-0.203412</td>\n",
       "      <td>-0.309521</td>\n",
       "      <td>-0.523189</td>\n",
       "      <td>0.022821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.303945</td>\n",
       "      <td>0.732523</td>\n",
       "      <td>0.551461</td>\n",
       "      <td>-0.690161</td>\n",
       "      <td>0.928490</td>\n",
       "      <td>0.908792</td>\n",
       "      <td>0.100185</td>\n",
       "      <td>0.380256</td>\n",
       "      <td>-0.258060</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.881259</td>\n",
       "      <td>-0.398592</td>\n",
       "      <td>-0.401772</td>\n",
       "      <td>-1.365810</td>\n",
       "      <td>1.102824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kings</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.645077</td>\n",
       "      <td>0.723860</td>\n",
       "      <td>-0.297817</td>\n",
       "      <td>0.955470</td>\n",
       "      <td>0.756911</td>\n",
       "      <td>-0.050575</td>\n",
       "      <td>0.879580</td>\n",
       "      <td>-0.352204</td>\n",
       "      <td>-0.542636</td>\n",
       "      <td>0.328233</td>\n",
       "      <td>-0.276544</td>\n",
       "      <td>-0.517881</td>\n",
       "      <td>-1.302085</td>\n",
       "      <td>1.190832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>-0.155346</td>\n",
       "      <td>0.398843</td>\n",
       "      <td>1.293184</td>\n",
       "      <td>-0.010472</td>\n",
       "      <td>0.653003</td>\n",
       "      <td>0.602013</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.627029</td>\n",
       "      <td>-0.486296</td>\n",
       "      <td>-0.198832</td>\n",
       "      <td>0.330482</td>\n",
       "      <td>-0.330293</td>\n",
       "      <td>-0.212875</td>\n",
       "      <td>-0.631169</td>\n",
       "      <td>0.266215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumps</th>\n",
       "      <td>-0.778245</td>\n",
       "      <td>0.525708</td>\n",
       "      <td>0.420622</td>\n",
       "      <td>-0.839927</td>\n",
       "      <td>-0.625751</td>\n",
       "      <td>0.449235</td>\n",
       "      <td>-0.172059</td>\n",
       "      <td>-0.387118</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.127919</td>\n",
       "      <td>-0.163383</td>\n",
       "      <td>1.282363</td>\n",
       "      <td>-0.343933</td>\n",
       "      <td>-1.110705</td>\n",
       "      <td>0.370962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toast</th>\n",
       "      <td>0.085310</td>\n",
       "      <td>0.376509</td>\n",
       "      <td>0.538755</td>\n",
       "      <td>-0.546762</td>\n",
       "      <td>0.863889</td>\n",
       "      <td>1.001641</td>\n",
       "      <td>-0.074441</td>\n",
       "      <td>0.972542</td>\n",
       "      <td>-0.316990</td>\n",
       "      <td>-0.437855</td>\n",
       "      <td>0.775675</td>\n",
       "      <td>-0.169660</td>\n",
       "      <td>-0.332431</td>\n",
       "      <td>-1.338063</td>\n",
       "      <td>1.218791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beans</th>\n",
       "      <td>0.228510</td>\n",
       "      <td>0.852703</td>\n",
       "      <td>0.759716</td>\n",
       "      <td>-0.359444</td>\n",
       "      <td>0.837258</td>\n",
       "      <td>1.151343</td>\n",
       "      <td>0.072233</td>\n",
       "      <td>0.645075</td>\n",
       "      <td>-0.267103</td>\n",
       "      <td>-0.284198</td>\n",
       "      <td>0.544412</td>\n",
       "      <td>-0.407798</td>\n",
       "      <td>-0.677250</td>\n",
       "      <td>-1.231492</td>\n",
       "      <td>1.111453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>-0.769255</td>\n",
       "      <td>-0.159452</td>\n",
       "      <td>1.009941</td>\n",
       "      <td>0.578341</td>\n",
       "      <td>-0.280634</td>\n",
       "      <td>-0.289808</td>\n",
       "      <td>0.947467</td>\n",
       "      <td>0.950760</td>\n",
       "      <td>-0.258595</td>\n",
       "      <td>0.948960</td>\n",
       "      <td>0.594117</td>\n",
       "      <td>0.836471</td>\n",
       "      <td>-0.475224</td>\n",
       "      <td>-0.504680</td>\n",
       "      <td>0.038407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5   \\\n",
       "sky       -0.639432 -0.024679  1.502709  0.610270 -0.721669 -0.316005   \n",
       "blue      -0.602743  0.073659  0.724945  0.157942 -0.789465  0.215237   \n",
       "lazy      -0.988989  0.319340  0.843687 -1.026609 -0.590684  0.173463   \n",
       "beautiful -0.544188 -0.353933  1.410363  0.720159 -0.013280 -0.414286   \n",
       "quick     -0.789416  0.323791  0.290438 -0.849889 -0.650918  0.278436   \n",
       "brown     -0.712770  0.695081  0.521078 -0.705848 -1.008142  0.141744   \n",
       "fox       -0.896241  0.404933  0.753256 -0.695366 -0.435905  0.327127   \n",
       "dog       -0.949771  0.453110  0.776009 -0.624677 -0.637290  0.142310   \n",
       "sausages   0.198648  0.176316  1.074163 -0.299473  1.010429  0.748644   \n",
       "ham        0.297497  0.631223  1.108528  0.457518  1.037477  1.027660   \n",
       "bacon      0.566377  0.017698  0.900351  0.066918  0.828408  1.132224   \n",
       "eggs       0.123760  0.780017  0.875009  0.150625  0.959082  0.564490   \n",
       "love      -0.394468  0.130106  0.939160  0.273528  0.538580 -0.035836   \n",
       "breakfast  0.303945  0.732523  0.551461 -0.690161  0.928490  0.908792   \n",
       "kings      0.000598  0.645077  0.723860 -0.297817  0.955470  0.756911   \n",
       "green     -0.155346  0.398843  1.293184 -0.010472  0.653003  0.602013   \n",
       "jumps     -0.778245  0.525708  0.420622 -0.839927 -0.625751  0.449235   \n",
       "toast      0.085310  0.376509  0.538755 -0.546762  0.863889  1.001641   \n",
       "beans      0.228510  0.852703  0.759716 -0.359444  0.837258  1.151343   \n",
       "today     -0.769255 -0.159452  1.009941  0.578341 -0.280634 -0.289808   \n",
       "\n",
       "                 6         7         8         9         10        11  \\\n",
       "sky        0.965002  1.001847 -0.234204  0.705497  0.514538  0.877368   \n",
       "blue       0.614432  0.679531 -0.048113  0.658686  0.095931  0.815805   \n",
       "lazy       0.259514 -0.637999  0.504987  0.112339 -0.474345  1.303706   \n",
       "beautiful  0.896078  0.552768 -0.145792  1.038409  0.312691  0.896521   \n",
       "quick     -0.141102 -0.187405  0.451341  0.482975  0.027598  1.579678   \n",
       "brown      0.080199 -0.064908  0.848459 -0.062610 -0.022713  1.501421   \n",
       "fox       -0.346009 -0.465849  0.637149  0.599076 -0.256180  1.590770   \n",
       "dog       -0.439198 -0.422219  0.756097  0.316867  0.205115  1.447336   \n",
       "sausages  -0.166153  0.556175 -0.244341  0.325445  0.850126 -0.310548   \n",
       "ham       -0.164433  0.289555 -0.268838 -0.167446  0.689474  0.043164   \n",
       "bacon      0.374976  0.695544 -0.307900  0.289053  0.316389 -0.160405   \n",
       "eggs      -0.189527  0.971184 -0.022017 -0.024021  0.362688 -0.340379   \n",
       "love       0.319965  0.581181 -0.265422  0.164804  0.601005 -0.203412   \n",
       "breakfast  0.100185  0.380256 -0.258060  0.202899  0.881259 -0.398592   \n",
       "kings     -0.050575  0.879580 -0.352204 -0.542636  0.328233 -0.276544   \n",
       "green      0.073694  0.627029 -0.486296 -0.198832  0.330482 -0.330293   \n",
       "jumps     -0.172059 -0.387118  0.585515  0.127919 -0.163383  1.282363   \n",
       "toast     -0.074441  0.972542 -0.316990 -0.437855  0.775675 -0.169660   \n",
       "beans      0.072233  0.645075 -0.267103 -0.284198  0.544412 -0.407798   \n",
       "today      0.947467  0.950760 -0.258595  0.948960  0.594117  0.836471   \n",
       "\n",
       "                 12        13        14  \n",
       "sky       -0.751616 -0.470609  0.071282  \n",
       "blue      -0.159200 -0.532422 -0.248695  \n",
       "lazy      -0.684338 -1.083380  0.311884  \n",
       "beautiful -0.635649 -0.480671  0.334769  \n",
       "quick     -0.351136 -1.142641  0.484352  \n",
       "brown     -0.514936 -0.974268  0.667429  \n",
       "fox       -0.236885 -0.898548  0.597680  \n",
       "dog       -0.020938 -0.981581  0.459399  \n",
       "sausages  -0.408820 -0.935457  0.673599  \n",
       "ham       -0.524910 -0.758180  0.730475  \n",
       "bacon     -0.618389 -1.018001  0.789529  \n",
       "eggs      -0.629636 -1.026932  0.675302  \n",
       "love      -0.309521 -0.523189  0.022821  \n",
       "breakfast -0.401772 -1.365810  1.102824  \n",
       "kings     -0.517881 -1.302085  1.190832  \n",
       "green     -0.212875 -0.631169  0.266215  \n",
       "jumps     -0.343933 -1.110705  0.370962  \n",
       "toast     -0.332431 -1.338063  1.218791  \n",
       "beans     -0.677250 -1.231492  1.111453  \n",
       "today     -0.475224 -0.504680  0.038407  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df = pd.DataFrame(wvs, index=words)\n",
    "vec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2d6bb-b393-45b7-8c62-066aff2155ac",
   "metadata": {},
   "source": [
    "Generamos la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "291975f4-5807-4ef7-9d68-1ee7d3febd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sky</th>\n",
       "      <th>blue</th>\n",
       "      <th>lazy</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>quick</th>\n",
       "      <th>brown</th>\n",
       "      <th>fox</th>\n",
       "      <th>dog</th>\n",
       "      <th>sausages</th>\n",
       "      <th>ham</th>\n",
       "      <th>bacon</th>\n",
       "      <th>eggs</th>\n",
       "      <th>love</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>kings</th>\n",
       "      <th>green</th>\n",
       "      <th>jumps</th>\n",
       "      <th>toast</th>\n",
       "      <th>beans</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sky</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884443</td>\n",
       "      <td>0.404548</td>\n",
       "      <td>0.928573</td>\n",
       "      <td>0.403114</td>\n",
       "      <td>0.446656</td>\n",
       "      <td>0.376840</td>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.277195</td>\n",
       "      <td>0.349490</td>\n",
       "      <td>0.310484</td>\n",
       "      <td>0.670830</td>\n",
       "      <td>0.134928</td>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.421173</td>\n",
       "      <td>0.311042</td>\n",
       "      <td>0.172593</td>\n",
       "      <td>0.185005</td>\n",
       "      <td>0.962221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.884443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.544603</td>\n",
       "      <td>0.769207</td>\n",
       "      <td>0.599867</td>\n",
       "      <td>0.584544</td>\n",
       "      <td>0.544614</td>\n",
       "      <td>0.545837</td>\n",
       "      <td>0.151053</td>\n",
       "      <td>0.112449</td>\n",
       "      <td>0.238992</td>\n",
       "      <td>0.161952</td>\n",
       "      <td>0.448391</td>\n",
       "      <td>0.067489</td>\n",
       "      <td>0.083450</td>\n",
       "      <td>0.277041</td>\n",
       "      <td>0.522448</td>\n",
       "      <td>0.100712</td>\n",
       "      <td>0.094574</td>\n",
       "      <td>0.871929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>0.404548</td>\n",
       "      <td>0.544603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.386370</td>\n",
       "      <td>0.906429</td>\n",
       "      <td>0.899321</td>\n",
       "      <td>0.914341</td>\n",
       "      <td>0.878318</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.104955</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.204776</td>\n",
       "      <td>0.200766</td>\n",
       "      <td>0.139880</td>\n",
       "      <td>0.944066</td>\n",
       "      <td>0.173519</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.341223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>0.928573</td>\n",
       "      <td>0.769207</td>\n",
       "      <td>0.386370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.376902</td>\n",
       "      <td>0.351269</td>\n",
       "      <td>0.404056</td>\n",
       "      <td>0.367527</td>\n",
       "      <td>0.358419</td>\n",
       "      <td>0.328147</td>\n",
       "      <td>0.413883</td>\n",
       "      <td>0.319331</td>\n",
       "      <td>0.682948</td>\n",
       "      <td>0.167741</td>\n",
       "      <td>0.195188</td>\n",
       "      <td>0.398091</td>\n",
       "      <td>0.262262</td>\n",
       "      <td>0.160075</td>\n",
       "      <td>0.171848</td>\n",
       "      <td>0.945873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick</th>\n",
       "      <td>0.403114</td>\n",
       "      <td>0.599867</td>\n",
       "      <td>0.906429</td>\n",
       "      <td>0.376902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>0.954882</td>\n",
       "      <td>0.941377</td>\n",
       "      <td>0.170716</td>\n",
       "      <td>0.120554</td>\n",
       "      <td>0.137238</td>\n",
       "      <td>0.133597</td>\n",
       "      <td>0.058925</td>\n",
       "      <td>0.270315</td>\n",
       "      <td>0.215114</td>\n",
       "      <td>0.066787</td>\n",
       "      <td>0.968901</td>\n",
       "      <td>0.257749</td>\n",
       "      <td>0.216935</td>\n",
       "      <td>0.394572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>0.446656</td>\n",
       "      <td>0.584544</td>\n",
       "      <td>0.899321</td>\n",
       "      <td>0.351269</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897303</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.129835</td>\n",
       "      <td>0.096733</td>\n",
       "      <td>0.164160</td>\n",
       "      <td>0.052679</td>\n",
       "      <td>0.222446</td>\n",
       "      <td>0.239225</td>\n",
       "      <td>0.083757</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.242752</td>\n",
       "      <td>0.239352</td>\n",
       "      <td>0.366445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.376840</td>\n",
       "      <td>0.544614</td>\n",
       "      <td>0.914341</td>\n",
       "      <td>0.404056</td>\n",
       "      <td>0.954882</td>\n",
       "      <td>0.897303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965174</td>\n",
       "      <td>0.183718</td>\n",
       "      <td>0.176364</td>\n",
       "      <td>0.129820</td>\n",
       "      <td>0.147126</td>\n",
       "      <td>0.068539</td>\n",
       "      <td>0.227387</td>\n",
       "      <td>0.190613</td>\n",
       "      <td>0.113491</td>\n",
       "      <td>0.952296</td>\n",
       "      <td>0.195343</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>0.353357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.545837</td>\n",
       "      <td>0.878318</td>\n",
       "      <td>0.367527</td>\n",
       "      <td>0.941377</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.965174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>0.161865</td>\n",
       "      <td>0.056952</td>\n",
       "      <td>0.135042</td>\n",
       "      <td>0.108004</td>\n",
       "      <td>0.217166</td>\n",
       "      <td>0.177226</td>\n",
       "      <td>0.116675</td>\n",
       "      <td>0.945430</td>\n",
       "      <td>0.202507</td>\n",
       "      <td>0.174167</td>\n",
       "      <td>0.354797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sausages</th>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.151053</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.358419</td>\n",
       "      <td>0.170716</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.183718</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883754</td>\n",
       "      <td>0.899111</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.755130</td>\n",
       "      <td>0.912560</td>\n",
       "      <td>0.855671</td>\n",
       "      <td>0.867339</td>\n",
       "      <td>0.161442</td>\n",
       "      <td>0.880381</td>\n",
       "      <td>0.888253</td>\n",
       "      <td>0.315121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0.277195</td>\n",
       "      <td>0.112449</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>0.328147</td>\n",
       "      <td>0.120554</td>\n",
       "      <td>0.129835</td>\n",
       "      <td>0.176364</td>\n",
       "      <td>0.161865</td>\n",
       "      <td>0.883754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>0.890548</td>\n",
       "      <td>0.682801</td>\n",
       "      <td>0.811592</td>\n",
       "      <td>0.843729</td>\n",
       "      <td>0.855219</td>\n",
       "      <td>0.158935</td>\n",
       "      <td>0.811822</td>\n",
       "      <td>0.882894</td>\n",
       "      <td>0.254957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>0.349490</td>\n",
       "      <td>0.238992</td>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.413883</td>\n",
       "      <td>0.137238</td>\n",
       "      <td>0.096733</td>\n",
       "      <td>0.129820</td>\n",
       "      <td>0.056952</td>\n",
       "      <td>0.899111</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853019</td>\n",
       "      <td>0.654689</td>\n",
       "      <td>0.846136</td>\n",
       "      <td>0.837929</td>\n",
       "      <td>0.806857</td>\n",
       "      <td>0.129091</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.883413</td>\n",
       "      <td>0.353559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0.310484</td>\n",
       "      <td>0.161952</td>\n",
       "      <td>0.104955</td>\n",
       "      <td>0.319331</td>\n",
       "      <td>0.133597</td>\n",
       "      <td>0.164160</td>\n",
       "      <td>0.147126</td>\n",
       "      <td>0.135042</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.890548</td>\n",
       "      <td>0.853019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742760</td>\n",
       "      <td>0.847655</td>\n",
       "      <td>0.924934</td>\n",
       "      <td>0.865969</td>\n",
       "      <td>0.162399</td>\n",
       "      <td>0.867630</td>\n",
       "      <td>0.919483</td>\n",
       "      <td>0.298116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.670830</td>\n",
       "      <td>0.448391</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.682948</td>\n",
       "      <td>0.058925</td>\n",
       "      <td>0.052679</td>\n",
       "      <td>0.068539</td>\n",
       "      <td>0.108004</td>\n",
       "      <td>0.755130</td>\n",
       "      <td>0.682801</td>\n",
       "      <td>0.654689</td>\n",
       "      <td>0.742760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.573420</td>\n",
       "      <td>0.626091</td>\n",
       "      <td>0.843869</td>\n",
       "      <td>0.027090</td>\n",
       "      <td>0.583890</td>\n",
       "      <td>0.598949</td>\n",
       "      <td>0.698342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.134928</td>\n",
       "      <td>0.067489</td>\n",
       "      <td>0.204776</td>\n",
       "      <td>0.167741</td>\n",
       "      <td>0.270315</td>\n",
       "      <td>0.222446</td>\n",
       "      <td>0.227387</td>\n",
       "      <td>0.217166</td>\n",
       "      <td>0.912560</td>\n",
       "      <td>0.811592</td>\n",
       "      <td>0.846136</td>\n",
       "      <td>0.847655</td>\n",
       "      <td>0.573420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899567</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>0.282219</td>\n",
       "      <td>0.929046</td>\n",
       "      <td>0.950689</td>\n",
       "      <td>0.159579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kings</th>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.083450</td>\n",
       "      <td>0.200766</td>\n",
       "      <td>0.195188</td>\n",
       "      <td>0.215114</td>\n",
       "      <td>0.239225</td>\n",
       "      <td>0.190613</td>\n",
       "      <td>0.177226</td>\n",
       "      <td>0.855671</td>\n",
       "      <td>0.843729</td>\n",
       "      <td>0.837929</td>\n",
       "      <td>0.924934</td>\n",
       "      <td>0.626091</td>\n",
       "      <td>0.899567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838363</td>\n",
       "      <td>0.253953</td>\n",
       "      <td>0.966309</td>\n",
       "      <td>0.966283</td>\n",
       "      <td>0.181938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>0.421173</td>\n",
       "      <td>0.277041</td>\n",
       "      <td>0.139880</td>\n",
       "      <td>0.398091</td>\n",
       "      <td>0.066787</td>\n",
       "      <td>0.083757</td>\n",
       "      <td>0.113491</td>\n",
       "      <td>0.116675</td>\n",
       "      <td>0.867339</td>\n",
       "      <td>0.855219</td>\n",
       "      <td>0.806857</td>\n",
       "      <td>0.865969</td>\n",
       "      <td>0.843869</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>0.838363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116068</td>\n",
       "      <td>0.786012</td>\n",
       "      <td>0.830885</td>\n",
       "      <td>0.382024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumps</th>\n",
       "      <td>0.311042</td>\n",
       "      <td>0.522448</td>\n",
       "      <td>0.944066</td>\n",
       "      <td>0.262262</td>\n",
       "      <td>0.968901</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.952296</td>\n",
       "      <td>0.945430</td>\n",
       "      <td>0.161442</td>\n",
       "      <td>0.158935</td>\n",
       "      <td>0.129091</td>\n",
       "      <td>0.162399</td>\n",
       "      <td>0.027090</td>\n",
       "      <td>0.282219</td>\n",
       "      <td>0.253953</td>\n",
       "      <td>0.116068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.267103</td>\n",
       "      <td>0.267155</td>\n",
       "      <td>0.264548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toast</th>\n",
       "      <td>0.172593</td>\n",
       "      <td>0.100712</td>\n",
       "      <td>0.173519</td>\n",
       "      <td>0.160075</td>\n",
       "      <td>0.257749</td>\n",
       "      <td>0.242752</td>\n",
       "      <td>0.195343</td>\n",
       "      <td>0.202507</td>\n",
       "      <td>0.880381</td>\n",
       "      <td>0.811822</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.867630</td>\n",
       "      <td>0.583890</td>\n",
       "      <td>0.929046</td>\n",
       "      <td>0.966309</td>\n",
       "      <td>0.786012</td>\n",
       "      <td>0.267103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950919</td>\n",
       "      <td>0.182520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beans</th>\n",
       "      <td>0.185005</td>\n",
       "      <td>0.094574</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.171848</td>\n",
       "      <td>0.216935</td>\n",
       "      <td>0.239352</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>0.174167</td>\n",
       "      <td>0.888253</td>\n",
       "      <td>0.882894</td>\n",
       "      <td>0.883413</td>\n",
       "      <td>0.919483</td>\n",
       "      <td>0.598949</td>\n",
       "      <td>0.950689</td>\n",
       "      <td>0.966283</td>\n",
       "      <td>0.830885</td>\n",
       "      <td>0.267155</td>\n",
       "      <td>0.950919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.962221</td>\n",
       "      <td>0.871929</td>\n",
       "      <td>0.341223</td>\n",
       "      <td>0.945873</td>\n",
       "      <td>0.394572</td>\n",
       "      <td>0.366445</td>\n",
       "      <td>0.353357</td>\n",
       "      <td>0.354797</td>\n",
       "      <td>0.315121</td>\n",
       "      <td>0.254957</td>\n",
       "      <td>0.353559</td>\n",
       "      <td>0.298116</td>\n",
       "      <td>0.698342</td>\n",
       "      <td>0.159579</td>\n",
       "      <td>0.181938</td>\n",
       "      <td>0.382024</td>\n",
       "      <td>0.264548</td>\n",
       "      <td>0.182520</td>\n",
       "      <td>0.159671</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sky      blue      lazy  beautiful     quick     brown  \\\n",
       "sky        1.000000  0.884443  0.404548   0.928573  0.403114  0.446656   \n",
       "blue       0.884443  1.000000  0.544603   0.769207  0.599867  0.584544   \n",
       "lazy       0.404548  0.544603  1.000000   0.386370  0.906429  0.899321   \n",
       "beautiful  0.928573  0.769207  0.386370   1.000000  0.376902  0.351269   \n",
       "quick      0.403114  0.599867  0.906429   0.376902  1.000000  0.931961   \n",
       "brown      0.446656  0.584544  0.899321   0.351269  0.931961  1.000000   \n",
       "fox        0.376840  0.544614  0.914341   0.404056  0.954882  0.897303   \n",
       "dog        0.388981  0.545837  0.878318   0.367527  0.941377  0.915842   \n",
       "sausages   0.293115  0.151053  0.123732   0.358419  0.170716  0.099398   \n",
       "ham        0.277195  0.112449  0.101477   0.328147  0.120554  0.129835   \n",
       "bacon      0.349490  0.238992  0.115611   0.413883  0.137238  0.096733   \n",
       "eggs       0.310484  0.161952  0.104955   0.319331  0.133597  0.164160   \n",
       "love       0.670830  0.448391  0.098807   0.682948  0.058925  0.052679   \n",
       "breakfast  0.134928  0.067489  0.204776   0.167741  0.270315  0.222446   \n",
       "kings      0.197749  0.083450  0.200766   0.195188  0.215114  0.239225   \n",
       "green      0.421173  0.277041  0.139880   0.398091  0.066787  0.083757   \n",
       "jumps      0.311042  0.522448  0.944066   0.262262  0.968901  0.947395   \n",
       "toast      0.172593  0.100712  0.173519   0.160075  0.257749  0.242752   \n",
       "beans      0.185005  0.094574  0.202247   0.171848  0.216935  0.239352   \n",
       "today      0.962221  0.871929  0.341223   0.945873  0.394572  0.366445   \n",
       "\n",
       "                fox       dog  sausages       ham     bacon      eggs  \\\n",
       "sky        0.376840  0.388981  0.293115  0.277195  0.349490  0.310484   \n",
       "blue       0.544614  0.545837  0.151053  0.112449  0.238992  0.161952   \n",
       "lazy       0.914341  0.878318  0.123732  0.101477  0.115611  0.104955   \n",
       "beautiful  0.404056  0.367527  0.358419  0.328147  0.413883  0.319331   \n",
       "quick      0.954882  0.941377  0.170716  0.120554  0.137238  0.133597   \n",
       "brown      0.897303  0.915842  0.099398  0.129835  0.096733  0.164160   \n",
       "fox        1.000000  0.965174  0.183718  0.176364  0.129820  0.147126   \n",
       "dog        0.965174  1.000000  0.174181  0.161865  0.056952  0.135042   \n",
       "sausages   0.183718  0.174181  1.000000  0.883754  0.899111  0.887931   \n",
       "ham        0.176364  0.161865  0.883754  1.000000  0.866839  0.890548   \n",
       "bacon      0.129820  0.056952  0.899111  0.866839  1.000000  0.853019   \n",
       "eggs       0.147126  0.135042  0.887931  0.890548  0.853019  1.000000   \n",
       "love       0.068539  0.108004  0.755130  0.682801  0.654689  0.742760   \n",
       "breakfast  0.227387  0.217166  0.912560  0.811592  0.846136  0.847655   \n",
       "kings      0.190613  0.177226  0.855671  0.843729  0.837929  0.924934   \n",
       "green      0.113491  0.116675  0.867339  0.855219  0.806857  0.865969   \n",
       "jumps      0.952296  0.945430  0.161442  0.158935  0.129091  0.162399   \n",
       "toast      0.195343  0.202507  0.880381  0.811822  0.841791  0.867630   \n",
       "beans      0.193750  0.174167  0.888253  0.882894  0.883413  0.919483   \n",
       "today      0.353357  0.354797  0.315121  0.254957  0.353559  0.298116   \n",
       "\n",
       "               love  breakfast     kings     green     jumps     toast  \\\n",
       "sky        0.670830   0.134928  0.197749  0.421173  0.311042  0.172593   \n",
       "blue       0.448391   0.067489  0.083450  0.277041  0.522448  0.100712   \n",
       "lazy       0.098807   0.204776  0.200766  0.139880  0.944066  0.173519   \n",
       "beautiful  0.682948   0.167741  0.195188  0.398091  0.262262  0.160075   \n",
       "quick      0.058925   0.270315  0.215114  0.066787  0.968901  0.257749   \n",
       "brown      0.052679   0.222446  0.239225  0.083757  0.947395  0.242752   \n",
       "fox        0.068539   0.227387  0.190613  0.113491  0.952296  0.195343   \n",
       "dog        0.108004   0.217166  0.177226  0.116675  0.945430  0.202507   \n",
       "sausages   0.755130   0.912560  0.855671  0.867339  0.161442  0.880381   \n",
       "ham        0.682801   0.811592  0.843729  0.855219  0.158935  0.811822   \n",
       "bacon      0.654689   0.846136  0.837929  0.806857  0.129091  0.841791   \n",
       "eggs       0.742760   0.847655  0.924934  0.865969  0.162399  0.867630   \n",
       "love       1.000000   0.573420  0.626091  0.843869  0.027090  0.583890   \n",
       "breakfast  0.573420   1.000000  0.899567  0.744333  0.282219  0.929046   \n",
       "kings      0.626091   0.899567  1.000000  0.838363  0.253953  0.966309   \n",
       "green      0.843869   0.744333  0.838363  1.000000  0.116068  0.786012   \n",
       "jumps      0.027090   0.282219  0.253953  0.116068  1.000000  0.267103   \n",
       "toast      0.583890   0.929046  0.966309  0.786012  0.267103  1.000000   \n",
       "beans      0.598949   0.950689  0.966283  0.830885  0.267155  0.950919   \n",
       "today      0.698342   0.159579  0.181938  0.382024  0.264548  0.182520   \n",
       "\n",
       "              beans     today  \n",
       "sky        0.185005  0.962221  \n",
       "blue       0.094574  0.871929  \n",
       "lazy       0.202247  0.341223  \n",
       "beautiful  0.171848  0.945873  \n",
       "quick      0.216935  0.394572  \n",
       "brown      0.239352  0.366445  \n",
       "fox        0.193750  0.353357  \n",
       "dog        0.174167  0.354797  \n",
       "sausages   0.888253  0.315121  \n",
       "ham        0.882894  0.254957  \n",
       "bacon      0.883413  0.353559  \n",
       "eggs       0.919483  0.298116  \n",
       "love       0.598949  0.698342  \n",
       "breakfast  0.950689  0.159579  \n",
       "kings      0.966283  0.181938  \n",
       "green      0.830885  0.382024  \n",
       "jumps      0.267155  0.264548  \n",
       "toast      0.950919  0.182520  \n",
       "beans      1.000000  0.159671  \n",
       "today      0.159671  1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(vec_df.values)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=words, columns=words)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad73e766-c420-4f64-a57a-c1fd34e5fa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sky           [today, beautiful, blue]\n",
       "blue           [sky, today, beautiful]\n",
       "lazy               [jumps, fox, quick]\n",
       "beautiful           [today, sky, blue]\n",
       "quick                [jumps, fox, dog]\n",
       "brown              [jumps, quick, dog]\n",
       "fox                [dog, quick, jumps]\n",
       "dog                [fox, jumps, quick]\n",
       "sausages     [breakfast, bacon, beans]\n",
       "ham            [eggs, sausages, beans]\n",
       "bacon           [sausages, beans, ham]\n",
       "eggs               [kings, beans, ham]\n",
       "love           [green, sausages, eggs]\n",
       "breakfast     [beans, toast, sausages]\n",
       "kings             [toast, beans, eggs]\n",
       "green            [sausages, eggs, ham]\n",
       "jumps              [quick, fox, brown]\n",
       "toast        [kings, beans, breakfast]\n",
       "beans        [kings, toast, breakfast]\n",
       "today           [sky, beautiful, blue]\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(words)\n",
    "similarity_df.apply(lambda row: feature_names[np.argsort(-row.values)[1:4]], \n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6a3c4fc-1026-48f8-972e-f258f0b85f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word vectors: 20000\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "total_vectors = len(nlp.vocab.vectors)\n",
    "\n",
    "print('Total word vectors:', total_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92527fbb-c5ff-4492-9851-c5f735f46435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>-0.773320</td>\n",
       "      <td>-0.282540</td>\n",
       "      <td>0.580760</td>\n",
       "      <td>0.841480</td>\n",
       "      <td>0.258540</td>\n",
       "      <td>0.585210</td>\n",
       "      <td>-0.021890</td>\n",
       "      <td>-0.463680</td>\n",
       "      <td>0.139070</td>\n",
       "      <td>0.65872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464470</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>-0.829200</td>\n",
       "      <td>0.354910</td>\n",
       "      <td>0.224530</td>\n",
       "      <td>-0.493920</td>\n",
       "      <td>0.456930</td>\n",
       "      <td>-0.649100</td>\n",
       "      <td>-0.131930</td>\n",
       "      <td>0.372040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumps</th>\n",
       "      <td>-0.334840</td>\n",
       "      <td>0.215990</td>\n",
       "      <td>-0.350440</td>\n",
       "      <td>-0.260020</td>\n",
       "      <td>0.411070</td>\n",
       "      <td>0.154010</td>\n",
       "      <td>-0.386110</td>\n",
       "      <td>0.206380</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>1.46050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107030</td>\n",
       "      <td>-0.279480</td>\n",
       "      <td>-0.186200</td>\n",
       "      <td>-0.543140</td>\n",
       "      <td>-0.479980</td>\n",
       "      <td>-0.284680</td>\n",
       "      <td>0.036022</td>\n",
       "      <td>0.190290</td>\n",
       "      <td>0.692290</td>\n",
       "      <td>-0.071501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>-0.401760</td>\n",
       "      <td>0.370570</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>-0.341250</td>\n",
       "      <td>0.049538</td>\n",
       "      <td>0.294400</td>\n",
       "      <td>-0.173760</td>\n",
       "      <td>-0.279820</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>2.16930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022908</td>\n",
       "      <td>-0.259290</td>\n",
       "      <td>-0.308620</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>-0.189620</td>\n",
       "      <td>0.547890</td>\n",
       "      <td>0.311940</td>\n",
       "      <td>0.246930</td>\n",
       "      <td>0.299290</td>\n",
       "      <td>-0.074861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sky</th>\n",
       "      <td>0.312550</td>\n",
       "      <td>-0.303080</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>-0.354940</td>\n",
       "      <td>0.100180</td>\n",
       "      <td>-0.141530</td>\n",
       "      <td>-0.514270</td>\n",
       "      <td>0.886110</td>\n",
       "      <td>-0.530540</td>\n",
       "      <td>1.55660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667050</td>\n",
       "      <td>0.279110</td>\n",
       "      <td>0.500970</td>\n",
       "      <td>-0.277580</td>\n",
       "      <td>-0.143720</td>\n",
       "      <td>0.342710</td>\n",
       "      <td>0.287580</td>\n",
       "      <td>0.537740</td>\n",
       "      <td>0.363490</td>\n",
       "      <td>0.496920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>-0.374120</td>\n",
       "      <td>-0.076264</td>\n",
       "      <td>0.109260</td>\n",
       "      <td>0.186620</td>\n",
       "      <td>0.029943</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>-0.631980</td>\n",
       "      <td>0.133060</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>0.60343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015404</td>\n",
       "      <td>0.392890</td>\n",
       "      <td>-0.034826</td>\n",
       "      <td>-0.720300</td>\n",
       "      <td>-0.365320</td>\n",
       "      <td>0.740510</td>\n",
       "      <td>0.108390</td>\n",
       "      <td>-0.365760</td>\n",
       "      <td>-0.288190</td>\n",
       "      <td>0.114630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.073378</td>\n",
       "      <td>0.227670</td>\n",
       "      <td>0.208420</td>\n",
       "      <td>-0.456790</td>\n",
       "      <td>-0.078219</td>\n",
       "      <td>0.601960</td>\n",
       "      <td>-0.024494</td>\n",
       "      <td>-0.467980</td>\n",
       "      <td>0.054627</td>\n",
       "      <td>2.28370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647710</td>\n",
       "      <td>0.373820</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>-0.033672</td>\n",
       "      <td>-0.073184</td>\n",
       "      <td>0.296830</td>\n",
       "      <td>0.340420</td>\n",
       "      <td>-0.599390</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>0.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.129450</td>\n",
       "      <td>0.036518</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>-0.060034</td>\n",
       "      <td>0.399840</td>\n",
       "      <td>-0.103020</td>\n",
       "      <td>-0.507880</td>\n",
       "      <td>0.076630</td>\n",
       "      <td>-0.422920</td>\n",
       "      <td>0.81573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501280</td>\n",
       "      <td>0.169010</td>\n",
       "      <td>0.548250</td>\n",
       "      <td>-0.319380</td>\n",
       "      <td>-0.072887</td>\n",
       "      <td>0.382950</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.182060</td>\n",
       "      <td>0.412640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sausages</th>\n",
       "      <td>-0.481340</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>0.396470</td>\n",
       "      <td>0.364770</td>\n",
       "      <td>-0.083069</td>\n",
       "      <td>0.684590</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>-0.210320</td>\n",
       "      <td>-0.021993</td>\n",
       "      <td>0.81876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602560</td>\n",
       "      <td>0.297010</td>\n",
       "      <td>-0.543030</td>\n",
       "      <td>-0.169150</td>\n",
       "      <td>-0.689910</td>\n",
       "      <td>-0.307360</td>\n",
       "      <td>0.193250</td>\n",
       "      <td>-0.634980</td>\n",
       "      <td>0.183010</td>\n",
       "      <td>0.285290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.139490</td>\n",
       "      <td>0.534530</td>\n",
       "      <td>-0.252470</td>\n",
       "      <td>-0.125650</td>\n",
       "      <td>0.048748</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.199060</td>\n",
       "      <td>-0.065970</td>\n",
       "      <td>0.128830</td>\n",
       "      <td>2.05590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124380</td>\n",
       "      <td>0.178440</td>\n",
       "      <td>-0.099469</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>-0.075513</td>\n",
       "      <td>-0.049069</td>\n",
       "      <td>-0.015228</td>\n",
       "      <td>0.088408</td>\n",
       "      <td>0.302170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>-0.430730</td>\n",
       "      <td>-0.016025</td>\n",
       "      <td>0.484620</td>\n",
       "      <td>0.101390</td>\n",
       "      <td>-0.299200</td>\n",
       "      <td>0.761820</td>\n",
       "      <td>-0.353130</td>\n",
       "      <td>-0.325290</td>\n",
       "      <td>0.156730</td>\n",
       "      <td>0.87321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304240</td>\n",
       "      <td>0.413440</td>\n",
       "      <td>-0.540730</td>\n",
       "      <td>-0.035930</td>\n",
       "      <td>-0.429450</td>\n",
       "      <td>-0.246590</td>\n",
       "      <td>0.161490</td>\n",
       "      <td>-1.065400</td>\n",
       "      <td>-0.244940</td>\n",
       "      <td>0.269540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>-0.417810</td>\n",
       "      <td>-0.035192</td>\n",
       "      <td>-0.126150</td>\n",
       "      <td>-0.215930</td>\n",
       "      <td>-0.669740</td>\n",
       "      <td>0.513250</td>\n",
       "      <td>-0.797090</td>\n",
       "      <td>-0.068611</td>\n",
       "      <td>0.634660</td>\n",
       "      <td>1.25630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232860</td>\n",
       "      <td>-0.139740</td>\n",
       "      <td>-0.681080</td>\n",
       "      <td>-0.370920</td>\n",
       "      <td>-0.545510</td>\n",
       "      <td>0.073728</td>\n",
       "      <td>0.111620</td>\n",
       "      <td>-0.324700</td>\n",
       "      <td>0.059721</td>\n",
       "      <td>0.159160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beans</th>\n",
       "      <td>-0.423290</td>\n",
       "      <td>-0.264500</td>\n",
       "      <td>0.200870</td>\n",
       "      <td>0.082187</td>\n",
       "      <td>0.066944</td>\n",
       "      <td>1.027600</td>\n",
       "      <td>-0.989140</td>\n",
       "      <td>-0.259950</td>\n",
       "      <td>0.145960</td>\n",
       "      <td>0.76645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048760</td>\n",
       "      <td>0.351680</td>\n",
       "      <td>-0.786260</td>\n",
       "      <td>-0.368790</td>\n",
       "      <td>-0.528640</td>\n",
       "      <td>0.287650</td>\n",
       "      <td>-0.273120</td>\n",
       "      <td>-1.114000</td>\n",
       "      <td>0.064322</td>\n",
       "      <td>0.223620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>-0.353320</td>\n",
       "      <td>-0.299710</td>\n",
       "      <td>-0.176230</td>\n",
       "      <td>-0.321940</td>\n",
       "      <td>-0.385640</td>\n",
       "      <td>0.586110</td>\n",
       "      <td>0.411160</td>\n",
       "      <td>-0.418680</td>\n",
       "      <td>0.073093</td>\n",
       "      <td>1.48650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402310</td>\n",
       "      <td>-0.038554</td>\n",
       "      <td>-0.288670</td>\n",
       "      <td>-0.244130</td>\n",
       "      <td>0.460990</td>\n",
       "      <td>0.514170</td>\n",
       "      <td>0.136260</td>\n",
       "      <td>0.344190</td>\n",
       "      <td>-0.845300</td>\n",
       "      <td>-0.077383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kings</th>\n",
       "      <td>0.259230</td>\n",
       "      <td>-0.854690</td>\n",
       "      <td>0.360010</td>\n",
       "      <td>-0.642000</td>\n",
       "      <td>0.568530</td>\n",
       "      <td>-0.321420</td>\n",
       "      <td>0.173250</td>\n",
       "      <td>0.133030</td>\n",
       "      <td>-0.089720</td>\n",
       "      <td>1.52860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.470090</td>\n",
       "      <td>0.063743</td>\n",
       "      <td>-0.545210</td>\n",
       "      <td>-0.192310</td>\n",
       "      <td>-0.301020</td>\n",
       "      <td>1.068500</td>\n",
       "      <td>0.231160</td>\n",
       "      <td>-0.147330</td>\n",
       "      <td>0.662490</td>\n",
       "      <td>-0.577420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>-0.072368</td>\n",
       "      <td>0.233200</td>\n",
       "      <td>0.137260</td>\n",
       "      <td>-0.156630</td>\n",
       "      <td>0.248440</td>\n",
       "      <td>0.349870</td>\n",
       "      <td>-0.241700</td>\n",
       "      <td>-0.091426</td>\n",
       "      <td>-0.530150</td>\n",
       "      <td>1.34130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.405170</td>\n",
       "      <td>0.243570</td>\n",
       "      <td>0.437300</td>\n",
       "      <td>-0.461520</td>\n",
       "      <td>-0.352710</td>\n",
       "      <td>0.336250</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>-0.111550</td>\n",
       "      <td>0.532930</td>\n",
       "      <td>0.712680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>-0.348680</td>\n",
       "      <td>-0.077720</td>\n",
       "      <td>0.177750</td>\n",
       "      <td>-0.094953</td>\n",
       "      <td>-0.452890</td>\n",
       "      <td>0.237790</td>\n",
       "      <td>0.209440</td>\n",
       "      <td>0.037886</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>0.89901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283050</td>\n",
       "      <td>0.270240</td>\n",
       "      <td>-0.654800</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>-0.068738</td>\n",
       "      <td>-0.534750</td>\n",
       "      <td>0.061783</td>\n",
       "      <td>0.123610</td>\n",
       "      <td>-0.553700</td>\n",
       "      <td>-0.544790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.534390</td>\n",
       "      <td>-0.348540</td>\n",
       "      <td>-0.097234</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>-0.170860</td>\n",
       "      <td>0.295650</td>\n",
       "      <td>-0.041816</td>\n",
       "      <td>-0.516550</td>\n",
       "      <td>2.11720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>0.104670</td>\n",
       "      <td>0.126310</td>\n",
       "      <td>0.120040</td>\n",
       "      <td>0.254380</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.207670</td>\n",
       "      <td>0.172580</td>\n",
       "      <td>0.063875</td>\n",
       "      <td>0.350990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>-0.156570</td>\n",
       "      <td>0.594890</td>\n",
       "      <td>-0.031445</td>\n",
       "      <td>-0.077586</td>\n",
       "      <td>0.278630</td>\n",
       "      <td>-0.509210</td>\n",
       "      <td>-0.066350</td>\n",
       "      <td>-0.081890</td>\n",
       "      <td>-0.047986</td>\n",
       "      <td>2.80360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326580</td>\n",
       "      <td>-0.413380</td>\n",
       "      <td>0.367910</td>\n",
       "      <td>-0.262630</td>\n",
       "      <td>-0.203690</td>\n",
       "      <td>-0.296560</td>\n",
       "      <td>-0.014873</td>\n",
       "      <td>-0.250060</td>\n",
       "      <td>-0.115940</td>\n",
       "      <td>0.083741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick</th>\n",
       "      <td>-0.445630</td>\n",
       "      <td>0.191510</td>\n",
       "      <td>-0.249210</td>\n",
       "      <td>0.465900</td>\n",
       "      <td>0.161950</td>\n",
       "      <td>0.212780</td>\n",
       "      <td>-0.046480</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.417660</td>\n",
       "      <td>1.68690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329460</td>\n",
       "      <td>0.421860</td>\n",
       "      <td>-0.039543</td>\n",
       "      <td>0.150180</td>\n",
       "      <td>0.338220</td>\n",
       "      <td>0.049554</td>\n",
       "      <td>0.149420</td>\n",
       "      <td>-0.038789</td>\n",
       "      <td>-0.019069</td>\n",
       "      <td>0.348650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toast</th>\n",
       "      <td>0.130740</td>\n",
       "      <td>-0.193730</td>\n",
       "      <td>0.253270</td>\n",
       "      <td>0.090102</td>\n",
       "      <td>-0.272580</td>\n",
       "      <td>-0.030571</td>\n",
       "      <td>0.096945</td>\n",
       "      <td>-0.115060</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.84838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142080</td>\n",
       "      <td>0.481910</td>\n",
       "      <td>0.045167</td>\n",
       "      <td>0.057151</td>\n",
       "      <td>-0.149520</td>\n",
       "      <td>-0.495130</td>\n",
       "      <td>-0.086677</td>\n",
       "      <td>-0.569040</td>\n",
       "      <td>-0.359290</td>\n",
       "      <td>0.097443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5    \\\n",
       "ham       -0.773320 -0.282540  0.580760  0.841480  0.258540  0.585210   \n",
       "jumps     -0.334840  0.215990 -0.350440 -0.260020  0.411070  0.154010   \n",
       "dog       -0.401760  0.370570  0.021281 -0.341250  0.049538  0.294400   \n",
       "sky        0.312550 -0.303080  0.019587 -0.354940  0.100180 -0.141530   \n",
       "brown     -0.374120 -0.076264  0.109260  0.186620  0.029943  0.182700   \n",
       "breakfast  0.073378  0.227670  0.208420 -0.456790 -0.078219  0.601960   \n",
       "blue       0.129450  0.036518  0.032298 -0.060034  0.399840 -0.103020   \n",
       "sausages  -0.481340  0.023467  0.396470  0.364770 -0.083069  0.684590   \n",
       "love       0.139490  0.534530 -0.252470 -0.125650  0.048748  0.152440   \n",
       "bacon     -0.430730 -0.016025  0.484620  0.101390 -0.299200  0.761820   \n",
       "eggs      -0.417810 -0.035192 -0.126150 -0.215930 -0.669740  0.513250   \n",
       "beans     -0.423290 -0.264500  0.200870  0.082187  0.066944  1.027600   \n",
       "lazy      -0.353320 -0.299710 -0.176230 -0.321940 -0.385640  0.586110   \n",
       "kings      0.259230 -0.854690  0.360010 -0.642000  0.568530 -0.321420   \n",
       "green     -0.072368  0.233200  0.137260 -0.156630  0.248440  0.349870   \n",
       "fox       -0.348680 -0.077720  0.177750 -0.094953 -0.452890  0.237790   \n",
       "beautiful  0.171200  0.534390 -0.348540 -0.097234  0.101800 -0.170860   \n",
       "today     -0.156570  0.594890 -0.031445 -0.077586  0.278630 -0.509210   \n",
       "quick     -0.445630  0.191510 -0.249210  0.465900  0.161950  0.212780   \n",
       "toast      0.130740 -0.193730  0.253270  0.090102 -0.272580 -0.030571   \n",
       "\n",
       "                6         7         8        9    ...       290       291  \\\n",
       "ham       -0.021890 -0.463680  0.139070  0.65872  ...  0.464470  0.481400   \n",
       "jumps     -0.386110  0.206380  0.386700  1.46050  ... -0.107030 -0.279480   \n",
       "dog       -0.173760 -0.279820  0.067622  2.16930  ...  0.022908 -0.259290   \n",
       "sky       -0.514270  0.886110 -0.530540  1.55660  ... -0.667050  0.279110   \n",
       "brown     -0.631980  0.133060 -0.128980  0.60343  ... -0.015404  0.392890   \n",
       "breakfast -0.024494 -0.467980  0.054627  2.28370  ...  0.647710  0.373820   \n",
       "blue      -0.507880  0.076630 -0.422920  0.81573  ... -0.501280  0.169010   \n",
       "sausages   0.007079 -0.210320 -0.021993  0.81876  ...  0.602560  0.297010   \n",
       "love       0.199060 -0.065970  0.128830  2.05590  ... -0.124380  0.178440   \n",
       "bacon     -0.353130 -0.325290  0.156730  0.87321  ...  0.304240  0.413440   \n",
       "eggs      -0.797090 -0.068611  0.634660  1.25630  ... -0.232860 -0.139740   \n",
       "beans     -0.989140 -0.259950  0.145960  0.76645  ...  0.048760  0.351680   \n",
       "lazy       0.411160 -0.418680  0.073093  1.48650  ...  0.402310 -0.038554   \n",
       "kings      0.173250  0.133030 -0.089720  1.52860  ... -0.470090  0.063743   \n",
       "green     -0.241700 -0.091426 -0.530150  1.34130  ... -0.405170  0.243570   \n",
       "fox        0.209440  0.037886  0.035064  0.89901  ... -0.283050  0.270240   \n",
       "beautiful  0.295650 -0.041816 -0.516550  2.11720  ... -0.285540  0.104670   \n",
       "today     -0.066350 -0.081890 -0.047986  2.80360  ... -0.326580 -0.413380   \n",
       "quick     -0.046480  0.021170  0.417660  1.68690  ... -0.329460  0.421860   \n",
       "toast      0.096945 -0.115060  0.484000  0.84838  ...  0.142080  0.481910   \n",
       "\n",
       "                292       293       294       295       296       297  \\\n",
       "ham       -0.829200  0.354910  0.224530 -0.493920  0.456930 -0.649100   \n",
       "jumps     -0.186200 -0.543140 -0.479980 -0.284680  0.036022  0.190290   \n",
       "dog       -0.308620  0.001754 -0.189620  0.547890  0.311940  0.246930   \n",
       "sky        0.500970 -0.277580 -0.143720  0.342710  0.287580  0.537740   \n",
       "brown     -0.034826 -0.720300 -0.365320  0.740510  0.108390 -0.365760   \n",
       "breakfast  0.019931 -0.033672 -0.073184  0.296830  0.340420 -0.599390   \n",
       "blue       0.548250 -0.319380 -0.072887  0.382950  0.237410  0.052289   \n",
       "sausages  -0.543030 -0.169150 -0.689910 -0.307360  0.193250 -0.634980   \n",
       "love      -0.099469  0.008682  0.089213 -0.075513 -0.049069 -0.015228   \n",
       "bacon     -0.540730 -0.035930 -0.429450 -0.246590  0.161490 -1.065400   \n",
       "eggs      -0.681080 -0.370920 -0.545510  0.073728  0.111620 -0.324700   \n",
       "beans     -0.786260 -0.368790 -0.528640  0.287650 -0.273120 -1.114000   \n",
       "lazy      -0.288670 -0.244130  0.460990  0.514170  0.136260  0.344190   \n",
       "kings     -0.545210 -0.192310 -0.301020  1.068500  0.231160 -0.147330   \n",
       "green      0.437300 -0.461520 -0.352710  0.336250  0.069899 -0.111550   \n",
       "fox       -0.654800  0.105300 -0.068738 -0.534750  0.061783  0.123610   \n",
       "beautiful  0.126310  0.120040  0.254380  0.247400  0.207670  0.172580   \n",
       "today      0.367910 -0.262630 -0.203690 -0.296560 -0.014873 -0.250060   \n",
       "quick     -0.039543  0.150180  0.338220  0.049554  0.149420 -0.038789   \n",
       "toast      0.045167  0.057151 -0.149520 -0.495130 -0.086677 -0.569040   \n",
       "\n",
       "                298       299  \n",
       "ham       -0.131930  0.372040  \n",
       "jumps      0.692290 -0.071501  \n",
       "dog        0.299290 -0.074861  \n",
       "sky        0.363490  0.496920  \n",
       "brown     -0.288190  0.114630  \n",
       "breakfast -0.061114  0.232200  \n",
       "blue       0.182060  0.412640  \n",
       "sausages   0.183010  0.285290  \n",
       "love       0.088408  0.302170  \n",
       "bacon     -0.244940  0.269540  \n",
       "eggs       0.059721  0.159160  \n",
       "beans      0.064322  0.223620  \n",
       "lazy      -0.845300 -0.077383  \n",
       "kings      0.662490 -0.577420  \n",
       "green      0.532930  0.712680  \n",
       "fox       -0.553700 -0.544790  \n",
       "beautiful  0.063875  0.350990  \n",
       "today     -0.115940  0.083741  \n",
       "quick     -0.019069  0.348650  \n",
       "toast     -0.359290  0.097443  \n",
       "\n",
       "[20 rows x 300 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = list(set([word for sublist in tokenized_corpus for word in sublist]))\n",
    "\n",
    "word_glove_vectors = np.array([nlp(word).vector for word in unique_words])\n",
    "vec_df = pd.DataFrame(word_glove_vectors, index=unique_words)\n",
    "vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ef6e28a-e5ef-4f62-af7c-24d0aca4b41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### t-SNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, n_iter=5000, perplexity=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(word_glove_vectors)\n",
    "labels = unique_words\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='red', edgecolors='r')\n",
    "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f33bafdb-4420-4566-9d0d-c573ff0dc3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>jumps</th>\n",
       "      <th>dog</th>\n",
       "      <th>sky</th>\n",
       "      <th>brown</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>blue</th>\n",
       "      <th>sausages</th>\n",
       "      <th>love</th>\n",
       "      <th>bacon</th>\n",
       "      <th>eggs</th>\n",
       "      <th>beans</th>\n",
       "      <th>lazy</th>\n",
       "      <th>kings</th>\n",
       "      <th>green</th>\n",
       "      <th>fox</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>today</th>\n",
       "      <th>quick</th>\n",
       "      <th>toast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046432</td>\n",
       "      <td>0.262579</td>\n",
       "      <td>0.174496</td>\n",
       "      <td>0.335111</td>\n",
       "      <td>0.371688</td>\n",
       "      <td>0.185452</td>\n",
       "      <td>0.710515</td>\n",
       "      <td>0.218128</td>\n",
       "      <td>0.738816</td>\n",
       "      <td>0.489116</td>\n",
       "      <td>0.495773</td>\n",
       "      <td>0.222571</td>\n",
       "      <td>0.127651</td>\n",
       "      <td>0.290761</td>\n",
       "      <td>0.209454</td>\n",
       "      <td>0.110936</td>\n",
       "      <td>0.104115</td>\n",
       "      <td>0.191665</td>\n",
       "      <td>0.500586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumps</th>\n",
       "      <td>0.046432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307960</td>\n",
       "      <td>0.278595</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.103865</td>\n",
       "      <td>0.187263</td>\n",
       "      <td>0.100810</td>\n",
       "      <td>0.185114</td>\n",
       "      <td>0.091021</td>\n",
       "      <td>0.150622</td>\n",
       "      <td>0.095544</td>\n",
       "      <td>0.222112</td>\n",
       "      <td>0.086659</td>\n",
       "      <td>0.150752</td>\n",
       "      <td>0.250834</td>\n",
       "      <td>0.142554</td>\n",
       "      <td>0.142099</td>\n",
       "      <td>0.301096</td>\n",
       "      <td>0.119099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.262579</td>\n",
       "      <td>0.307960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219087</td>\n",
       "      <td>0.341204</td>\n",
       "      <td>0.295957</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.326413</td>\n",
       "      <td>0.358715</td>\n",
       "      <td>0.295123</td>\n",
       "      <td>0.291202</td>\n",
       "      <td>0.230778</td>\n",
       "      <td>0.301678</td>\n",
       "      <td>0.156674</td>\n",
       "      <td>0.272693</td>\n",
       "      <td>0.485855</td>\n",
       "      <td>0.280658</td>\n",
       "      <td>0.223730</td>\n",
       "      <td>0.299892</td>\n",
       "      <td>0.182994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sky</th>\n",
       "      <td>0.174496</td>\n",
       "      <td>0.278595</td>\n",
       "      <td>0.219087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408844</td>\n",
       "      <td>0.205429</td>\n",
       "      <td>0.627800</td>\n",
       "      <td>0.077070</td>\n",
       "      <td>0.351084</td>\n",
       "      <td>0.172964</td>\n",
       "      <td>0.223585</td>\n",
       "      <td>0.160064</td>\n",
       "      <td>0.259361</td>\n",
       "      <td>0.263785</td>\n",
       "      <td>0.488385</td>\n",
       "      <td>0.303459</td>\n",
       "      <td>0.428081</td>\n",
       "      <td>0.256770</td>\n",
       "      <td>0.192515</td>\n",
       "      <td>0.216372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>0.335111</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.341204</td>\n",
       "      <td>0.408844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277158</td>\n",
       "      <td>0.683011</td>\n",
       "      <td>0.404895</td>\n",
       "      <td>0.331943</td>\n",
       "      <td>0.432891</td>\n",
       "      <td>0.466903</td>\n",
       "      <td>0.453427</td>\n",
       "      <td>0.256875</td>\n",
       "      <td>0.193487</td>\n",
       "      <td>0.646850</td>\n",
       "      <td>0.406912</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.147418</td>\n",
       "      <td>0.217009</td>\n",
       "      <td>0.347578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.371688</td>\n",
       "      <td>0.103865</td>\n",
       "      <td>0.295957</td>\n",
       "      <td>0.205429</td>\n",
       "      <td>0.277158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197103</td>\n",
       "      <td>0.484660</td>\n",
       "      <td>0.245735</td>\n",
       "      <td>0.487737</td>\n",
       "      <td>0.431108</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.161841</td>\n",
       "      <td>0.288437</td>\n",
       "      <td>0.165064</td>\n",
       "      <td>0.314472</td>\n",
       "      <td>0.288788</td>\n",
       "      <td>0.358221</td>\n",
       "      <td>0.513436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.185452</td>\n",
       "      <td>0.187263</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.627800</td>\n",
       "      <td>0.683011</td>\n",
       "      <td>0.197103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.184090</td>\n",
       "      <td>0.364961</td>\n",
       "      <td>0.242987</td>\n",
       "      <td>0.297546</td>\n",
       "      <td>0.261304</td>\n",
       "      <td>0.230513</td>\n",
       "      <td>0.207656</td>\n",
       "      <td>0.764083</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.461366</td>\n",
       "      <td>0.180088</td>\n",
       "      <td>0.220331</td>\n",
       "      <td>0.232264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sausages</th>\n",
       "      <td>0.710515</td>\n",
       "      <td>0.100810</td>\n",
       "      <td>0.326413</td>\n",
       "      <td>0.077070</td>\n",
       "      <td>0.404895</td>\n",
       "      <td>0.484660</td>\n",
       "      <td>0.184090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229077</td>\n",
       "      <td>0.823075</td>\n",
       "      <td>0.565044</td>\n",
       "      <td>0.596148</td>\n",
       "      <td>0.227305</td>\n",
       "      <td>0.100838</td>\n",
       "      <td>0.333903</td>\n",
       "      <td>0.214655</td>\n",
       "      <td>0.135784</td>\n",
       "      <td>0.133225</td>\n",
       "      <td>0.260431</td>\n",
       "      <td>0.543087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.218128</td>\n",
       "      <td>0.185114</td>\n",
       "      <td>0.358715</td>\n",
       "      <td>0.351084</td>\n",
       "      <td>0.331943</td>\n",
       "      <td>0.245735</td>\n",
       "      <td>0.364961</td>\n",
       "      <td>0.229077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292268</td>\n",
       "      <td>0.254177</td>\n",
       "      <td>0.249891</td>\n",
       "      <td>0.339280</td>\n",
       "      <td>0.263805</td>\n",
       "      <td>0.327302</td>\n",
       "      <td>0.255050</td>\n",
       "      <td>0.594738</td>\n",
       "      <td>0.371650</td>\n",
       "      <td>0.292446</td>\n",
       "      <td>0.274246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>0.738816</td>\n",
       "      <td>0.091021</td>\n",
       "      <td>0.295123</td>\n",
       "      <td>0.172964</td>\n",
       "      <td>0.432891</td>\n",
       "      <td>0.487737</td>\n",
       "      <td>0.242987</td>\n",
       "      <td>0.823075</td>\n",
       "      <td>0.292268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620539</td>\n",
       "      <td>0.617909</td>\n",
       "      <td>0.264376</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.386664</td>\n",
       "      <td>0.210082</td>\n",
       "      <td>0.151157</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>0.265370</td>\n",
       "      <td>0.622701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0.489116</td>\n",
       "      <td>0.150622</td>\n",
       "      <td>0.291202</td>\n",
       "      <td>0.223585</td>\n",
       "      <td>0.466903</td>\n",
       "      <td>0.431108</td>\n",
       "      <td>0.297546</td>\n",
       "      <td>0.565044</td>\n",
       "      <td>0.254177</td>\n",
       "      <td>0.620539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585053</td>\n",
       "      <td>0.236769</td>\n",
       "      <td>0.118818</td>\n",
       "      <td>0.392072</td>\n",
       "      <td>0.247314</td>\n",
       "      <td>0.214437</td>\n",
       "      <td>0.183048</td>\n",
       "      <td>0.245487</td>\n",
       "      <td>0.495935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beans</th>\n",
       "      <td>0.495773</td>\n",
       "      <td>0.095544</td>\n",
       "      <td>0.230778</td>\n",
       "      <td>0.160064</td>\n",
       "      <td>0.453427</td>\n",
       "      <td>0.378215</td>\n",
       "      <td>0.261304</td>\n",
       "      <td>0.596148</td>\n",
       "      <td>0.249891</td>\n",
       "      <td>0.617909</td>\n",
       "      <td>0.585053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.245672</td>\n",
       "      <td>0.092759</td>\n",
       "      <td>0.462498</td>\n",
       "      <td>0.118537</td>\n",
       "      <td>0.165268</td>\n",
       "      <td>0.147652</td>\n",
       "      <td>0.251534</td>\n",
       "      <td>0.449284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>0.222571</td>\n",
       "      <td>0.222112</td>\n",
       "      <td>0.301678</td>\n",
       "      <td>0.259361</td>\n",
       "      <td>0.256875</td>\n",
       "      <td>0.319941</td>\n",
       "      <td>0.230513</td>\n",
       "      <td>0.227305</td>\n",
       "      <td>0.339280</td>\n",
       "      <td>0.264376</td>\n",
       "      <td>0.236769</td>\n",
       "      <td>0.245672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190515</td>\n",
       "      <td>0.230945</td>\n",
       "      <td>0.267240</td>\n",
       "      <td>0.294308</td>\n",
       "      <td>0.286802</td>\n",
       "      <td>0.400060</td>\n",
       "      <td>0.231329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kings</th>\n",
       "      <td>0.127651</td>\n",
       "      <td>0.086659</td>\n",
       "      <td>0.156674</td>\n",
       "      <td>0.263785</td>\n",
       "      <td>0.193487</td>\n",
       "      <td>0.161841</td>\n",
       "      <td>0.207656</td>\n",
       "      <td>0.100838</td>\n",
       "      <td>0.263805</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.118818</td>\n",
       "      <td>0.092759</td>\n",
       "      <td>0.190515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151519</td>\n",
       "      <td>0.226735</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.204743</td>\n",
       "      <td>0.127679</td>\n",
       "      <td>0.125741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>0.290761</td>\n",
       "      <td>0.150752</td>\n",
       "      <td>0.272693</td>\n",
       "      <td>0.488385</td>\n",
       "      <td>0.646850</td>\n",
       "      <td>0.288437</td>\n",
       "      <td>0.764083</td>\n",
       "      <td>0.333903</td>\n",
       "      <td>0.327302</td>\n",
       "      <td>0.386664</td>\n",
       "      <td>0.392072</td>\n",
       "      <td>0.462498</td>\n",
       "      <td>0.230945</td>\n",
       "      <td>0.151519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.392392</td>\n",
       "      <td>0.246754</td>\n",
       "      <td>0.287504</td>\n",
       "      <td>0.287608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.209454</td>\n",
       "      <td>0.250834</td>\n",
       "      <td>0.485855</td>\n",
       "      <td>0.303459</td>\n",
       "      <td>0.406912</td>\n",
       "      <td>0.165064</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.214655</td>\n",
       "      <td>0.255050</td>\n",
       "      <td>0.210082</td>\n",
       "      <td>0.247314</td>\n",
       "      <td>0.118537</td>\n",
       "      <td>0.267240</td>\n",
       "      <td>0.226735</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210050</td>\n",
       "      <td>0.150072</td>\n",
       "      <td>0.192686</td>\n",
       "      <td>0.163371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>0.110936</td>\n",
       "      <td>0.142554</td>\n",
       "      <td>0.280658</td>\n",
       "      <td>0.428081</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.314472</td>\n",
       "      <td>0.461366</td>\n",
       "      <td>0.135784</td>\n",
       "      <td>0.594738</td>\n",
       "      <td>0.151157</td>\n",
       "      <td>0.214437</td>\n",
       "      <td>0.165268</td>\n",
       "      <td>0.294308</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.392392</td>\n",
       "      <td>0.210050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.314184</td>\n",
       "      <td>0.289178</td>\n",
       "      <td>0.189482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.104115</td>\n",
       "      <td>0.142099</td>\n",
       "      <td>0.223730</td>\n",
       "      <td>0.256770</td>\n",
       "      <td>0.147418</td>\n",
       "      <td>0.288788</td>\n",
       "      <td>0.180088</td>\n",
       "      <td>0.133225</td>\n",
       "      <td>0.371650</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>0.183048</td>\n",
       "      <td>0.147652</td>\n",
       "      <td>0.286802</td>\n",
       "      <td>0.204743</td>\n",
       "      <td>0.246754</td>\n",
       "      <td>0.150072</td>\n",
       "      <td>0.314184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370023</td>\n",
       "      <td>0.174257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick</th>\n",
       "      <td>0.191665</td>\n",
       "      <td>0.301096</td>\n",
       "      <td>0.299892</td>\n",
       "      <td>0.192515</td>\n",
       "      <td>0.217009</td>\n",
       "      <td>0.358221</td>\n",
       "      <td>0.220331</td>\n",
       "      <td>0.260431</td>\n",
       "      <td>0.292446</td>\n",
       "      <td>0.265370</td>\n",
       "      <td>0.245487</td>\n",
       "      <td>0.251534</td>\n",
       "      <td>0.400060</td>\n",
       "      <td>0.127679</td>\n",
       "      <td>0.287504</td>\n",
       "      <td>0.192686</td>\n",
       "      <td>0.289178</td>\n",
       "      <td>0.370023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toast</th>\n",
       "      <td>0.500586</td>\n",
       "      <td>0.119099</td>\n",
       "      <td>0.182994</td>\n",
       "      <td>0.216372</td>\n",
       "      <td>0.347578</td>\n",
       "      <td>0.513436</td>\n",
       "      <td>0.232264</td>\n",
       "      <td>0.543087</td>\n",
       "      <td>0.274246</td>\n",
       "      <td>0.622701</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.449284</td>\n",
       "      <td>0.231329</td>\n",
       "      <td>0.125741</td>\n",
       "      <td>0.287608</td>\n",
       "      <td>0.163371</td>\n",
       "      <td>0.189482</td>\n",
       "      <td>0.174257</td>\n",
       "      <td>0.292624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ham     jumps       dog       sky     brown  breakfast  \\\n",
       "ham        1.000000  0.046432  0.262579  0.174496  0.335111   0.371688   \n",
       "jumps      0.046432  1.000000  0.307960  0.278595  0.110400   0.103865   \n",
       "dog        0.262579  0.307960  1.000000  0.219087  0.341204   0.295957   \n",
       "sky        0.174496  0.278595  0.219087  1.000000  0.408844   0.205429   \n",
       "brown      0.335111  0.110400  0.341204  0.408844  1.000000   0.277158   \n",
       "breakfast  0.371688  0.103865  0.295957  0.205429  0.277158   1.000000   \n",
       "blue       0.185452  0.187263  0.314065  0.627800  0.683011   0.197103   \n",
       "sausages   0.710515  0.100810  0.326413  0.077070  0.404895   0.484660   \n",
       "love       0.218128  0.185114  0.358715  0.351084  0.331943   0.245735   \n",
       "bacon      0.738816  0.091021  0.295123  0.172964  0.432891   0.487737   \n",
       "eggs       0.489116  0.150622  0.291202  0.223585  0.466903   0.431108   \n",
       "beans      0.495773  0.095544  0.230778  0.160064  0.453427   0.378215   \n",
       "lazy       0.222571  0.222112  0.301678  0.259361  0.256875   0.319941   \n",
       "kings      0.127651  0.086659  0.156674  0.263785  0.193487   0.161841   \n",
       "green      0.290761  0.150752  0.272693  0.488385  0.646850   0.288437   \n",
       "fox        0.209454  0.250834  0.485855  0.303459  0.406912   0.165064   \n",
       "beautiful  0.110936  0.142554  0.280658  0.428081  0.355700   0.314472   \n",
       "today      0.104115  0.142099  0.223730  0.256770  0.147418   0.288788   \n",
       "quick      0.191665  0.301096  0.299892  0.192515  0.217009   0.358221   \n",
       "toast      0.500586  0.119099  0.182994  0.216372  0.347578   0.513436   \n",
       "\n",
       "               blue  sausages      love     bacon      eggs     beans  \\\n",
       "ham        0.185452  0.710515  0.218128  0.738816  0.489116  0.495773   \n",
       "jumps      0.187263  0.100810  0.185114  0.091021  0.150622  0.095544   \n",
       "dog        0.314065  0.326413  0.358715  0.295123  0.291202  0.230778   \n",
       "sky        0.627800  0.077070  0.351084  0.172964  0.223585  0.160064   \n",
       "brown      0.683011  0.404895  0.331943  0.432891  0.466903  0.453427   \n",
       "breakfast  0.197103  0.484660  0.245735  0.487737  0.431108  0.378215   \n",
       "blue       1.000000  0.184090  0.364961  0.242987  0.297546  0.261304   \n",
       "sausages   0.184090  1.000000  0.229077  0.823075  0.565044  0.596148   \n",
       "love       0.364961  0.229077  1.000000  0.292268  0.254177  0.249891   \n",
       "bacon      0.242987  0.823075  0.292268  1.000000  0.620539  0.617909   \n",
       "eggs       0.297546  0.565044  0.254177  0.620539  1.000000  0.585053   \n",
       "beans      0.261304  0.596148  0.249891  0.617909  0.585053  1.000000   \n",
       "lazy       0.230513  0.227305  0.339280  0.264376  0.236769  0.245672   \n",
       "kings      0.207656  0.100838  0.263805  0.146716  0.118818  0.092759   \n",
       "green      0.764083  0.333903  0.327302  0.386664  0.392072  0.462498   \n",
       "fox        0.371178  0.214655  0.255050  0.210082  0.247314  0.118537   \n",
       "beautiful  0.461366  0.135784  0.594738  0.151157  0.214437  0.165268   \n",
       "today      0.180088  0.133225  0.371650  0.158949  0.183048  0.147652   \n",
       "quick      0.220331  0.260431  0.292446  0.265370  0.245487  0.251534   \n",
       "toast      0.232264  0.543087  0.274246  0.622701  0.495935  0.449284   \n",
       "\n",
       "               lazy     kings     green       fox  beautiful     today  \\\n",
       "ham        0.222571  0.127651  0.290761  0.209454   0.110936  0.104115   \n",
       "jumps      0.222112  0.086659  0.150752  0.250834   0.142554  0.142099   \n",
       "dog        0.301678  0.156674  0.272693  0.485855   0.280658  0.223730   \n",
       "sky        0.259361  0.263785  0.488385  0.303459   0.428081  0.256770   \n",
       "brown      0.256875  0.193487  0.646850  0.406912   0.355700  0.147418   \n",
       "breakfast  0.319941  0.161841  0.288437  0.165064   0.314472  0.288788   \n",
       "blue       0.230513  0.207656  0.764083  0.371178   0.461366  0.180088   \n",
       "sausages   0.227305  0.100838  0.333903  0.214655   0.135784  0.133225   \n",
       "love       0.339280  0.263805  0.327302  0.255050   0.594738  0.371650   \n",
       "bacon      0.264376  0.146716  0.386664  0.210082   0.151157  0.158949   \n",
       "eggs       0.236769  0.118818  0.392072  0.247314   0.214437  0.183048   \n",
       "beans      0.245672  0.092759  0.462498  0.118537   0.165268  0.147652   \n",
       "lazy       1.000000  0.190515  0.230945  0.267240   0.294308  0.286802   \n",
       "kings      0.190515  1.000000  0.151519  0.226735   0.158615  0.204743   \n",
       "green      0.230945  0.151519  1.000000  0.323800   0.392392  0.246754   \n",
       "fox        0.267240  0.226735  0.323800  1.000000   0.210050  0.150072   \n",
       "beautiful  0.294308  0.158615  0.392392  0.210050   1.000000  0.314184   \n",
       "today      0.286802  0.204743  0.246754  0.150072   0.314184  1.000000   \n",
       "quick      0.400060  0.127679  0.287504  0.192686   0.289178  0.370023   \n",
       "toast      0.231329  0.125741  0.287608  0.163371   0.189482  0.174257   \n",
       "\n",
       "              quick     toast  \n",
       "ham        0.191665  0.500586  \n",
       "jumps      0.301096  0.119099  \n",
       "dog        0.299892  0.182994  \n",
       "sky        0.192515  0.216372  \n",
       "brown      0.217009  0.347578  \n",
       "breakfast  0.358221  0.513436  \n",
       "blue       0.220331  0.232264  \n",
       "sausages   0.260431  0.543087  \n",
       "love       0.292446  0.274246  \n",
       "bacon      0.265370  0.622701  \n",
       "eggs       0.245487  0.495935  \n",
       "beans      0.251534  0.449284  \n",
       "lazy       0.400060  0.231329  \n",
       "kings      0.127679  0.125741  \n",
       "green      0.287504  0.287608  \n",
       "fox        0.192686  0.163371  \n",
       "beautiful  0.289178  0.189482  \n",
       "today      0.370023  0.174257  \n",
       "quick      1.000000  0.292624  \n",
       "toast      0.292624  1.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Semantic similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(vec_df.values)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=unique_words, columns=unique_words)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f28a28b9-5e54-4200-955a-47c0bb80b691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham              [bacon, sausages, toast]\n",
       "jumps                   [dog, quick, sky]\n",
       "dog                    [fox, love, brown]\n",
       "sky              [blue, green, beautiful]\n",
       "brown                 [blue, green, eggs]\n",
       "breakfast        [toast, bacon, sausages]\n",
       "blue                  [green, brown, sky]\n",
       "sausages              [bacon, ham, beans]\n",
       "love             [beautiful, today, blue]\n",
       "bacon              [sausages, ham, toast]\n",
       "eggs             [bacon, beans, sausages]\n",
       "beans             [bacon, sausages, eggs]\n",
       "lazy             [quick, love, breakfast]\n",
       "kings                    [love, sky, fox]\n",
       "green                  [blue, brown, sky]\n",
       "fox                    [dog, brown, blue]\n",
       "beautiful               [love, blue, sky]\n",
       "today            [love, quick, beautiful]\n",
       "quick            [lazy, today, breakfast]\n",
       "toast        [bacon, sausages, breakfast]\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.array(unique_words)\n",
    "similarity_df.apply(lambda row: feature_names[np.argsort(-row.values)[1:4]], \n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59a2dd-82ee-49a6-b53d-2e46d62c77a9",
   "metadata": {},
   "source": [
    "### The FastText Model \n",
    "\n",
    "A extension of vanilla World2Vec, Facebook 2016. \n",
    "El paper https://arxiv.org/pdf/1607.04606.pdf. \n",
    "\n",
    "Para el World2Vec cada palabra es un unidad de medidad, pero para FastText cada palabra esta compuesta de n-grams, por eso se llama un subword model. \n",
    "\n",
    "En general se genera entre 3 y 6 n-grams. Esto hace que exista mayor probabilidad de una buena representacion de palabras extrañas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e96b26-4781-4cf7-94ae-a8532ea994d6",
   "metadata": {},
   "source": [
    "#### Robust FastText Model with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25f661de-44bc-4c8b-857f-440637506bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.fasttext.FastText at 0x2384a3ba5b0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 15    # Word vector dimensionality  \n",
    "window_context = 20  # Context window size                                                                                    \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "sample = 1e-3        # Downsample setting for frequent words\n",
    "sg = 1               # skip-gram model\n",
    "\n",
    "ft_model = FastText(tokenized_corpus, vector_size=feature_size, \n",
    "                     window=window_context, min_count = min_word_count,\n",
    "                     sg=sg, sample=sample, epochs=5000)\n",
    "ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02ad0704-911b-4aac-be39-d88b40f03a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "words = ft_model.wv.index_to_key\n",
    "wvs = ft_model.wv[words]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, n_iter=5000, perplexity=5)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(wvs)\n",
    "labels = words\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='green', edgecolors='k')\n",
    "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f28d279-927a-4cf5-b85e-cf1ffdd03ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3631966\n",
      "0.9523557\n"
     ]
    }
   ],
   "source": [
    "### Similirities\n",
    "print(ft_model.wv.similarity(w1='ham', w2='sky'))\n",
    "print(ft_model.wv.similarity(w1='ham', w2='sausages'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b972f-8191-46dd-ac3d-34af1a84da6a",
   "metadata": {},
   "source": [
    "### Getting document level embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b8e0a6c-88ac-4905-8de6-67c48dafbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key )\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f344fd0a-73da-4ae7-9c1f-526f07e16491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633224</td>\n",
       "      <td>0.241109</td>\n",
       "      <td>1.336286</td>\n",
       "      <td>0.227798</td>\n",
       "      <td>-0.196780</td>\n",
       "      <td>-0.039579</td>\n",
       "      <td>0.184827</td>\n",
       "      <td>0.730348</td>\n",
       "      <td>0.824477</td>\n",
       "      <td>0.126218</td>\n",
       "      <td>-0.025842</td>\n",
       "      <td>-0.348504</td>\n",
       "      <td>0.098324</td>\n",
       "      <td>-0.786467</td>\n",
       "      <td>0.234595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558180</td>\n",
       "      <td>0.151005</td>\n",
       "      <td>1.171184</td>\n",
       "      <td>0.287862</td>\n",
       "      <td>-0.219503</td>\n",
       "      <td>-0.049056</td>\n",
       "      <td>0.193210</td>\n",
       "      <td>0.688771</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.177741</td>\n",
       "      <td>-0.110026</td>\n",
       "      <td>-0.388595</td>\n",
       "      <td>0.054427</td>\n",
       "      <td>-0.672323</td>\n",
       "      <td>0.224093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.714791</td>\n",
       "      <td>-0.460922</td>\n",
       "      <td>1.369773</td>\n",
       "      <td>-0.143889</td>\n",
       "      <td>0.404819</td>\n",
       "      <td>0.906332</td>\n",
       "      <td>0.107537</td>\n",
       "      <td>0.466878</td>\n",
       "      <td>0.489146</td>\n",
       "      <td>-0.690582</td>\n",
       "      <td>0.451690</td>\n",
       "      <td>0.332470</td>\n",
       "      <td>-0.088589</td>\n",
       "      <td>-0.898453</td>\n",
       "      <td>-0.215381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.369935</td>\n",
       "      <td>-0.693844</td>\n",
       "      <td>0.548159</td>\n",
       "      <td>0.798238</td>\n",
       "      <td>-0.120878</td>\n",
       "      <td>0.261229</td>\n",
       "      <td>0.257672</td>\n",
       "      <td>1.025583</td>\n",
       "      <td>-0.979814</td>\n",
       "      <td>0.572465</td>\n",
       "      <td>-0.527470</td>\n",
       "      <td>-0.788771</td>\n",
       "      <td>-0.573670</td>\n",
       "      <td>-0.596745</td>\n",
       "      <td>0.486590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005354</td>\n",
       "      <td>-0.499769</td>\n",
       "      <td>0.598558</td>\n",
       "      <td>0.644029</td>\n",
       "      <td>-0.199926</td>\n",
       "      <td>0.119552</td>\n",
       "      <td>0.221546</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>-0.690052</td>\n",
       "      <td>0.469918</td>\n",
       "      <td>-0.544808</td>\n",
       "      <td>-0.664936</td>\n",
       "      <td>-0.435627</td>\n",
       "      <td>-0.498187</td>\n",
       "      <td>0.462443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.524913</td>\n",
       "      <td>-0.349459</td>\n",
       "      <td>1.343731</td>\n",
       "      <td>-0.115450</td>\n",
       "      <td>0.314273</td>\n",
       "      <td>0.762364</td>\n",
       "      <td>0.118351</td>\n",
       "      <td>0.495899</td>\n",
       "      <td>0.555722</td>\n",
       "      <td>-0.595158</td>\n",
       "      <td>0.390288</td>\n",
       "      <td>0.242537</td>\n",
       "      <td>-0.047782</td>\n",
       "      <td>-0.861928</td>\n",
       "      <td>-0.161288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.675773</td>\n",
       "      <td>0.260902</td>\n",
       "      <td>1.350646</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>-0.224001</td>\n",
       "      <td>-0.084514</td>\n",
       "      <td>0.198552</td>\n",
       "      <td>0.759499</td>\n",
       "      <td>0.851364</td>\n",
       "      <td>0.165621</td>\n",
       "      <td>-0.023771</td>\n",
       "      <td>-0.400847</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>-0.789908</td>\n",
       "      <td>0.229319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.698170</td>\n",
       "      <td>-0.448786</td>\n",
       "      <td>1.392484</td>\n",
       "      <td>-0.131797</td>\n",
       "      <td>0.401764</td>\n",
       "      <td>0.901194</td>\n",
       "      <td>0.105864</td>\n",
       "      <td>0.462250</td>\n",
       "      <td>0.512573</td>\n",
       "      <td>-0.685103</td>\n",
       "      <td>0.454156</td>\n",
       "      <td>0.336223</td>\n",
       "      <td>-0.081693</td>\n",
       "      <td>-0.904762</td>\n",
       "      <td>-0.211872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.633224  0.241109  1.336286  0.227798 -0.196780 -0.039579  0.184827   \n",
       "1  0.558180  0.151005  1.171184  0.287862 -0.219503 -0.049056  0.193210   \n",
       "2 -0.714791 -0.460922  1.369773 -0.143889  0.404819  0.906332  0.107537   \n",
       "3 -0.369935 -0.693844  0.548159  0.798238 -0.120878  0.261229  0.257672   \n",
       "4 -0.005354 -0.499769  0.598558  0.644029 -0.199926  0.119552  0.221546   \n",
       "5 -0.524913 -0.349459  1.343731 -0.115450  0.314273  0.762364  0.118351   \n",
       "6  0.675773  0.260902  1.350646  0.276515 -0.224001 -0.084514  0.198552   \n",
       "7 -0.698170 -0.448786  1.392484 -0.131797  0.401764  0.901194  0.105864   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.730348  0.824477  0.126218 -0.025842 -0.348504  0.098324 -0.786467   \n",
       "1  0.688771  0.583352  0.177741 -0.110026 -0.388595  0.054427 -0.672323   \n",
       "2  0.466878  0.489146 -0.690582  0.451690  0.332470 -0.088589 -0.898453   \n",
       "3  1.025583 -0.979814  0.572465 -0.527470 -0.788771 -0.573670 -0.596745   \n",
       "4  0.770649 -0.690052  0.469918 -0.544808 -0.664936 -0.435627 -0.498187   \n",
       "5  0.495899  0.555722 -0.595158  0.390288  0.242537 -0.047782 -0.861928   \n",
       "6  0.759499  0.851364  0.165621 -0.023771 -0.400847  0.123324 -0.789908   \n",
       "7  0.462250  0.512573 -0.685103  0.454156  0.336223 -0.081693 -0.904762   \n",
       "\n",
       "         14  \n",
       "0  0.234595  \n",
       "1  0.224093  \n",
       "2 -0.215381  \n",
       "3  0.486590  \n",
       "4  0.462443  \n",
       "5 -0.161288  \n",
       "6  0.229319  \n",
       "7 -0.211872  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get document level embeddings\n",
    "ft_doc_features = averaged_word_vectorizer(corpus=tokenized_corpus, model=ft_model,\n",
    "                                             num_features=feature_size)\n",
    "pd.DataFrame(ft_doc_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238956a1-f46c-49ce-9022-b7fe668bcb33",
   "metadata": {},
   "source": [
    "#### Ex Clustering with AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "996a1185-97f7-435d-a296-4b4624c8712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ignacio.sepulveda\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document  \\\n",
       "0                                      The sky is blue and beautiful.   \n",
       "1                                   Love this blue and beautiful sky!   \n",
       "2                        The quick brown fox jumps over the lazy dog.   \n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans   \n",
       "4                         I love green eggs, ham, sausages and bacon!   \n",
       "5                    The brown fox is quick and the blue dog is lazy!   \n",
       "6            The sky is very blue and the sky is very beautiful today   \n",
       "7                         The dog is lazy but the brown fox is quick!   \n",
       "\n",
       "  Category  ClusterLabel  \n",
       "0  weather             0  \n",
       "1  weather             0  \n",
       "2  animals             2  \n",
       "3     food             1  \n",
       "4     food             1  \n",
       "5  animals             2  \n",
       "6  weather             0  \n",
       "7  animals             2  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "ap = AffinityPropagation()\n",
    "ap.fit(ft_doc_features)\n",
    "\n",
    "cluster_labels = ap.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, \n",
    "                              columns=['ClusterLabel'])\n",
    "\n",
    "pd.concat([corpus_df, cluster_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966aee50-cf70-4578-917d-68bf5f3057a4",
   "metadata": {},
   "source": [
    "Clasifica bien, y no secesita la etiqueta solo las embeddings feature desde word2vec. Para visualizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44da255e-1b67-4ea6-87f5-3db3fed31110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pcs = pca.fit_transform(ft_doc_features)\n",
    "labels = ap.labels_\n",
    "categories = list(corpus_df['Category'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    label = labels[i]\n",
    "    color = 'orange' if label == 0 else 'blue' if label == 1 else 'green'\n",
    "    annotation_label = categories[i]\n",
    "    x, y = pcs[i]\n",
    "    plt.scatter(x, y, c=color, edgecolors='k')\n",
    "    plt.annotate(annotation_label, xy=(x+1e-2, y+1e-2), xytext=(0, 0), \n",
    "                 textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc070c-4442-4b7a-9038-13238ab061aa",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Movie Recommendations with Document Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf35263-c4e8-4f7f-8bb4-cfc2b4216942",
   "metadata": {},
   "source": [
    "En general hay tres formas de hacer recomendadores:\n",
    "    \n",
    "   * Simple Rule-based Reccomenders: Se basa en especificas metricas globales y limites, como popularity, global ratings etcs.\n",
    "   \n",
    "   * Content-based Recommenders: el nombre lo dice\n",
    "   \n",
    "   * Colaborative filtering: Usamos info historica de otros usuarios. \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63c2c9ef-eca1-457b-9165-8ee3d27ee7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8c0651b-c1eb-4f87-8fff-3a39a7cd21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                4803 non-null   int64  \n",
      " 1   genres                4803 non-null   object \n",
      " 2   homepage              1712 non-null   object \n",
      " 3   id                    4803 non-null   int64  \n",
      " 4   keywords              4803 non-null   object \n",
      " 5   original_language     4803 non-null   object \n",
      " 6   original_title        4803 non-null   object \n",
      " 7   overview              4800 non-null   object \n",
      " 8   popularity            4803 non-null   float64\n",
      " 9   production_companies  4803 non-null   object \n",
      " 10  production_countries  4803 non-null   object \n",
      " 11  release_date          4802 non-null   object \n",
      " 12  revenue               4803 non-null   int64  \n",
      " 13  runtime               4801 non-null   float64\n",
      " 14  spoken_languages      4803 non-null   object \n",
      " 15  status                4803 non-null   object \n",
      " 16  tagline               3959 non-null   object \n",
      " 17  title                 4803 non-null   object \n",
      " 18  vote_average          4803 non-null   float64\n",
      " 19  vote_count            4803 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2010%20-%20Project%208%20-%20Movie%20Recommendations%20with%20Document%20Similarity/tmdb_5000_movies.csv.gz', compression='gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "925da65d-7bcd-4e76-a417-f698a0da09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4800 entries, 546 to 4553\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        4800 non-null   object \n",
      " 1   tagline      4800 non-null   object \n",
      " 2   overview     4800 non-null   object \n",
      " 3   popularity   4800 non-null   float64\n",
      " 4   description  4800 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 225.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[['title', 'tagline', 'overview', 'popularity']]\n",
    "df.tagline.fillna('', inplace=True)\n",
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "df.dropna(inplace=True)\n",
    "df = df.sort_values(by=['popularity'], ascending=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c77381-4bab-44d9-961c-b02a4a77028f",
   "metadata": {},
   "source": [
    "### Document Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899cf1c-da01-4f57-9073-3815183764a7",
   "metadata": {},
   "source": [
    "#### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354e304-a8db-4a1b-8459-a41d9546632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    #filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1abc8-728e-4437-91da-e7e513f1cab4",
   "metadata": {},
   "source": [
    "### Extract TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28345566-f6c3-4e9a-babb-e1b6e3842847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 20471)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f86075-f02d-4732-96a9-ec9c229044d3",
   "metadata": {},
   "source": [
    "### Compute Pairwise Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08259afe-748d-45d3-aff8-22b1e7dcf840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060846</td>\n",
       "      <td>0.025039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036237</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022064</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.036561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076033</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.043475</td>\n",
       "      <td>0.011465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5     6         7     \\\n",
       "0  1.000000  0.000000  0.000000  0.000000  0.006071  0.008067   0.0  0.000000   \n",
       "1  0.000000  1.000000  0.000000  0.017839  0.007968  0.000000   0.0  0.012501   \n",
       "2  0.000000  0.000000  1.000000  0.000000  0.017178  0.000000   0.0  0.000000   \n",
       "3  0.000000  0.017839  0.000000  1.000000  0.000000  0.022414   0.0  0.000000   \n",
       "4  0.006071  0.007968  0.017178  0.000000  1.000000  0.004673   0.0  0.064581   \n",
       "\n",
       "   8         9     ...      4790      4791      4792  4793      4794  \\\n",
       "0   0.0  0.000000  ...  0.018758  0.000000  0.037930   0.0  0.000000   \n",
       "1   0.0  0.014840  ...  0.000000  0.000000  0.017564   0.0  0.019152   \n",
       "2   0.0  0.024326  ...  0.000000  0.006903  0.005024   0.0  0.012893   \n",
       "3   0.0  0.037207  ...  0.000000  0.060846  0.025039   0.0  0.036237   \n",
       "4   0.0  0.000000  ...  0.022064  0.019662  0.036561   0.0  0.015826   \n",
       "\n",
       "       4795      4796      4797      4798      4799  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.009646  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.007963  \n",
       "2  0.000000  0.025975  0.000000  0.027126  0.009340  \n",
       "3  0.030516  0.022605  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.076033  0.004516  0.043475  0.011465  \n",
       "\n",
       "[5 rows x 4800 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d072e-c606-4fea-bb94-c577509a8537",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5680a05d-e303-40ab-8bf7-89dab4ca2aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Minions', 'Interstellar', 'Deadpool', ..., 'Penitentiary',\n",
       "        'Alien Zone', 'America Is Still the Place'], dtype=object),\n",
       " (4800,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list = df['title'].values\n",
    "movies_list, movies_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a9b012e-c0a3-430a-b7dc-7a403c0c16d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_minions 0\n",
      "Similitudues [1.         0.         0.         ... 0.         0.         0.00964646]\n",
      "top 5 [ 33  60 737 490 298]\n",
      "Nombres top 5 ['Despicable Me 2' 'Despicable Me'\n",
      " 'Teenage Mutant Ninja Turtles: Out of the Shadows' 'Superman'\n",
      " 'Rise of the Guardians']\n"
     ]
    }
   ],
   "source": [
    "## Movie id\n",
    "movie_idx = np.where(movies_list == 'Minions')[0][0]\n",
    "print(f'id_minions {movie_idx}')\n",
    "\n",
    "## Similarities\n",
    "movie_similarities = doc_sim_df.iloc[movie_idx].values\n",
    "print(f'Similitudues {movie_similarities}')\n",
    "\n",
    "## id de 5 con mayor similitud\n",
    "similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "print(f'top 5 {similar_movie_idxs}')\n",
    "\n",
    "## Nombres\n",
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "similar_movies\n",
    "print(f'Nombres top 5 {similar_movies}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7186a-a75b-44ae-a18a-c3da8639976f",
   "metadata": {},
   "source": [
    "#### Get popular movie Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f4a10d96-8b41-48b6-b0a1-6a24710f8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
    "    # find movie id\n",
    "    movie_idx = np.where(movies == movie_title)[0][0]\n",
    "    # get movie similarities\n",
    "    movie_similarities = doc_sims.iloc[movie_idx].values\n",
    "    # get top 5 similar movie IDs\n",
    "    similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "    # get top 5 movies\n",
    "    similar_movies = movies[similar_movie_idxs]\n",
    "    # return the top 5 movies\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2524f675-a8ed-4cd5-a92c-e717773ebe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
    "              'Dawn of the Planet of the Apes', 'The Hunger Games: Mockingjay - Part 1', 'Terminator Genisys', \n",
    "              'Captain America: Civil War', 'The Dark Knight', 'The Martian', 'Batman v Superman: Dawn of Justice', \n",
    "              'Pulp Fiction', 'The Godfather', 'The Shawshank Redemption', 'The Lord of the Rings: The Fellowship of the Ring',  \n",
    "              'Harry Potter and the Chamber of Secrets', 'Star Wars', 'The Hobbit: The Battle of the Five Armies',\n",
    "              'Iron Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "031f6a6d-cef7-49ff-ba87-cbc4cdd5b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Minions\n",
      "Top 5 recommended Movies: ['Despicable Me 2' 'Despicable Me'\n",
      " 'Teenage Mutant Ninja Turtles: Out of the Shadows' 'Superman'\n",
      " 'Rise of the Guardians']\n",
      "\n",
      "Movie: Interstellar\n",
      "Top 5 recommended Movies: ['Gattaca' 'Space Pirate Captain Harlock' 'Space Cowboys'\n",
      " 'Starship Troopers' 'Final Destination 2']\n",
      "\n",
      "Movie: Deadpool\n",
      "Top 5 recommended Movies: ['Silent Trigger' 'Underworld: Evolution' 'Bronson' 'Shaft' 'Don Jon']\n",
      "\n",
      "Movie: Jurassic World\n",
      "Top 5 recommended Movies: ['Jurassic Park' 'The Lost World: Jurassic Park'\n",
      " \"National Lampoon's Vacation\" 'The Nut Job' 'Vacation']\n",
      "\n",
      "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
      "Top 5 recommended Movies: [\"Pirates of the Caribbean: Dead Man's Chest\"\n",
      " 'Pirates of the Caribbean: On Stranger Tides' 'The Pirate'\n",
      " 'The Pirates! In an Adventure with Scientists!' 'Joyful Noise']\n",
      "\n",
      "Movie: Dawn of the Planet of the Apes\n",
      "Top 5 recommended Movies: ['Battle for the Planet of the Apes' 'Groove' 'The Other End of the Line'\n",
      " 'Chicago Overcoat' 'Definitely, Maybe']\n",
      "\n",
      "Movie: The Hunger Games: Mockingjay - Part 1\n",
      "Top 5 recommended Movies: ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'John Carter' 'For Greater Glory - The True Story of Cristiada'\n",
      " 'The Proposition']\n",
      "\n",
      "Movie: Terminator Genisys\n",
      "Top 5 recommended Movies: ['Terminator 2: Judgment Day' 'Terminator Salvation'\n",
      " 'Terminator 3: Rise of the Machines' 'Mad Max'\n",
      " 'X-Men: Days of Future Past']\n",
      "\n",
      "Movie: Captain America: Civil War\n",
      "Top 5 recommended Movies: ['Captain America: The Winter Soldier' 'This Means War'\n",
      " 'Avengers: Age of Ultron' 'Iron Man 2' 'Escape from Tomorrow']\n",
      "\n",
      "Movie: The Dark Knight\n",
      "Top 5 recommended Movies: ['The Dark Knight Rises' 'Batman Forever' 'Batman Returns'\n",
      " 'Batman: The Dark Knight Returns, Part 2' 'JFK']\n",
      "\n",
      "Movie: The Martian\n",
      "Top 5 recommended Movies: ['The Last Days on Mars' 'Swept Away' 'Alive' 'All Is Lost' 'Red Planet']\n",
      "\n",
      "Movie: Batman v Superman: Dawn of Justice\n",
      "Top 5 recommended Movies: ['Batman Returns' 'The Punisher' 'Defendor'\n",
      " 'Batman: The Dark Knight Returns, Part 2' 'Nowhere to Run']\n",
      "\n",
      "Movie: Pulp Fiction\n",
      "Top 5 recommended Movies: ['Sliding Doors' 'You Kill Me' 'New York Stories' 'Timecrimes'\n",
      " 'All or Nothing']\n",
      "\n",
      "Movie: The Godfather\n",
      "Top 5 recommended Movies: ['The Godfather: Part II' 'Blood Ties' 'Made' 'Lords of London'\n",
      " 'Easy Money']\n",
      "\n",
      "Movie: The Shawshank Redemption\n",
      "Top 5 recommended Movies: ['Civil Brand' 'Les Misérables' 'The Chorus' 'Prison' 'Fortress']\n",
      "\n",
      "Movie: The Lord of the Rings: The Fellowship of the Ring\n",
      "Top 5 recommended Movies: ['The Lord of the Rings: The Two Towers'\n",
      " 'The Hobbit: The Desolation of Smaug'\n",
      " 'The Lord of the Rings: The Return of the King'\n",
      " \"What's the Worst That Could Happen?\" 'The Hobbit: An Unexpected Journey']\n",
      "\n",
      "Movie: Harry Potter and the Chamber of Secrets\n",
      "Top 5 recommended Movies: ['Harry Potter and the Prisoner of Azkaban'\n",
      " 'Harry Potter and the Goblet of Fire'\n",
      " 'Harry Potter and the Order of the Phoenix'\n",
      " 'Harry Potter and the Half-Blood Prince'\n",
      " \"Harry Potter and the Philosopher's Stone\"]\n",
      "\n",
      "Movie: Star Wars\n",
      "Top 5 recommended Movies: ['The Empire Strikes Back' 'Return of the Jedi' 'Shrek the Third'\n",
      " 'The Ice Pirates' 'The Tale of Despereaux']\n",
      "\n",
      "Movie: The Hobbit: The Battle of the Five Armies\n",
      "Top 5 recommended Movies: ['The Hobbit: The Desolation of Smaug' 'The Hobbit: An Unexpected Journey'\n",
      " \"Dragon Nest: Warriors' Dawn\"\n",
      " 'A Funny Thing Happened on the Way to the Forum' 'X-Men: Apocalypse']\n",
      "\n",
      "Movie: Iron Man\n",
      "Top 5 recommended Movies: ['Iron Man 2' 'Avengers: Age of Ultron' 'Hostage' 'Iron Man 3'\n",
      " 'Baahubali: The Beginning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie in popular_movies:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c03bd-e1ec-4f6e-96b5-8fc566ddd745",
   "metadata": {},
   "source": [
    "## Predicting E-Commerce Product Reccomendation Raings from Reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e8df2ce-ffb6-450e-955c-bde704bf7dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i co...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                            \n",
       "1           1         1080   34                            \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                                                                                                                                                                               Review Text  \\\n",
       "0                                                                                                                                                    Absolutely wonderful - silky and sexy and comfortable   \n",
       "1  Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length...   \n",
       "2  I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i co...   \n",
       "3                                                                             I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!   \n",
       "4         This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!   \n",
       "\n",
       "   Rating  Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0       4                1                        0       Initmates   \n",
       "1       5                1                        4         General   \n",
       "2       3                0                        0         General   \n",
       "3       5                1                        0  General Petite   \n",
       "4       5                1                        6         General   \n",
       "\n",
       "  Department Name Class Name  \n",
       "0        Intimate  Intimates  \n",
       "1         Dresses    Dresses  \n",
       "2         Dresses    Dresses  \n",
       "3         Bottoms      Pants  \n",
       "4            Tops    Blouses  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Basic dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "## Data \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dipanjanS/feature_engineering_session_dhs18/master/ecommerce_product_ratings_prediction/Womens%20Clothing%20E-Commerce%20Reviews.csv', keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69639fff-223b-4747-8d01-303f3c3c1fff",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c8972225-9bcb-4dc6-981e-11d3cee9c4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    Review  \\\n",
       "0                                                                                                                                                    Absolutely wonderful - silky and sexy and comfortable   \n",
       "1  Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length...   \n",
       "2  Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so...   \n",
       "3                                                            My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!   \n",
       "4  Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love ...   \n",
       "\n",
       "   Rating  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'] = (df['Title'].map(str) +' '+ df['Review Text']).apply(lambda row: row.strip())\n",
    "df['Rating'] = [1 if rating > 3 else 0 for rating in df['Rating']]\n",
    "df = df[['Review', 'Rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aa0fa37a-1471-443b-9a15-9f1038531939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22642 entries, 0 to 23485\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  22642 non-null  object\n",
      " 1   Rating  22642 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 530.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " 1    17449\n",
       " 0     5193\n",
       " Name: Rating, dtype: int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## removemos los sin review\n",
    "df = df[df['Review'] != '']\n",
    "df.info(),df['Rating'].value_counts() # imbalance data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed54b61-ca65-4abd-b950-2eb8061123f5",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2eec6f34-383a-41c6-a43c-68b890b3f005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16981, 1), (5661, 1))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Review']], df['Rating'], random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7559ea2c-ff91-4810-95d1-1becb777d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 13059, 0: 3922}), Counter({1: 4390, 0: 1271}))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14582508-e1a0-4809-bd3f-a43453316381",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "Solo con count data. \n",
    "\n",
    "* **Word Count**: total number of words in the documents\n",
    "* **Character Count**: total number of characters in the documents\n",
    "* **Average Word Density**: average length of the words used in the documents\n",
    "* **Puncutation Count**: total number of punctuation marks in the documents\n",
    "* **Upper Case Count**: total number of upper count words in the documents\n",
    "* **Title Word Count**: total number of proper case (title) words in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb0bd7ae-e494-4a58-8669-060245b67a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "X_train['char_count'] = X_train['Review'].apply(len)\n",
    "X_train['word_count'] = X_train['Review'].apply(lambda x: len(x.split()))\n",
    "X_train['word_density'] = X_train['char_count'] / (X_train['word_count']+1)\n",
    "X_train['punctuation_count'] = X_train['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_train['title_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_train['upper_case_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "\n",
    "X_test['char_count'] = X_test['Review'].apply(len)\n",
    "X_test['word_count'] = X_test['Review'].apply(lambda x: len(x.split()))\n",
    "X_test['word_density'] = X_test['char_count'] / (X_test['word_count']+1)\n",
    "X_test['punctuation_count'] = X_test['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_test['title_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_test['upper_case_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c74e62f-8fbb-4565-8041-a531405d41bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                        Review  \\\n",
       "12896  Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....   \n",
       "13183  Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...   \n",
       "1496   I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...   \n",
       "5205   Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...   \n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...   \n",
       "\n",
       "       char_count  word_count  word_density  punctuation_count  \\\n",
       "12896         268          52      5.056604                  8   \n",
       "13183         399          84      4.694118                 20   \n",
       "1496          525         104      5.000000                 19   \n",
       "5205          203          35      5.638889                 10   \n",
       "13366         295          51      5.673077                 22   \n",
       "\n",
       "       title_word_count  upper_case_word_count  \n",
       "12896                 2                      0  \n",
       "13183                 2                      1  \n",
       "1496                  2                      2  \n",
       "5205                  2                      0  \n",
       "13366                 2                      0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbba377-9ddb-46f0-96c7-f60d2bae6bc9",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c68ab62-f3c3-4459-b79c-b98f4ce1f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d87d6-bda1-43c4-ba3c-37a245ce41c6",
   "metadata": {},
   "source": [
    "##### Model Evaluation and Metrics - Quick Refresher. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b34d0-3120-46ea-8682-3e4aa1e63ffe",
   "metadata": {},
   "source": [
    "* **Precision**: The positive predictive power of a model. Out of all the predictions made by a model for a class, how many are actually correct\n",
    "* **Recall**: The coverage or hit-rate of a model. Out of all the test data samples belonging to a class, how many was the model able to predict (hit or cover) correctly.\n",
    "* **F1-score**: The harmonic mean of the precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366f633-8447-45dd-98d1-e42bbbf032a5",
   "metadata": {},
   "source": [
    "Do check out ROC Curve, AUC Score and PR Curve also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6458191d-48c7-407a-bd95-023dc0fa4c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1271\n",
      "           1       0.78      1.00      0.87      4390\n",
      "\n",
      "    accuracy                           0.78      5661\n",
      "   macro avg       0.39      0.50      0.44      5661\n",
      "weighted avg       0.60      0.78      0.68      5661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ignacio.sepulveda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ignacio.sepulveda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ignacio.sepulveda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1\n",
       "0  0  1271\n",
       "1  0  4390"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train)\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a481f-9866-4c52-ac81-77be74b42e5a",
   "metadata": {},
   "source": [
    "La matriz de confusion muestra que solo predecimos rating 1, vale popo el logic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc61e56-6a88-4c22-8b47-f474646b465a",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ac22a-50fa-4569-aa1d-3d2dc2c97ede",
   "metadata": {},
   "source": [
    "#### Features Text Sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3725e-7a2e-427e-b7ee-860402285aa6",
   "metadata": {},
   "source": [
    "Textblob nos permite calcular la polaridad de una oracion, y su subjetitvidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "93c0ec97-fae1-4754-b439-c706487b8661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.7500000000000001, subjectivity=0.9)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "\n",
    "textblob.TextBlob('This is an AMAZING pair of Jeans!').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da6ed3da-2602-48a6-9845-b718194fceb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.95, subjectivity=0.85)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.TextBlob('I really hated this UGLY T-shirt!!').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c44ddd49-938c-4e34-b828-4dd2e3c79ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_snt_obj = X_train['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "X_train['Subjectivity'] = [obj.subjectivity for obj in x_train_snt_obj.values]\n",
    "\n",
    "x_test_snt_obj = X_test['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
    "X_test['Subjectivity'] = [obj.subjectivity for obj in x_test_snt_obj.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dbdbfae6-1ee1-4ae1-81b4-7fe5466fb30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                        Review  \\\n",
       "12896  Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....   \n",
       "13183  Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...   \n",
       "1496   I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...   \n",
       "5205   Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...   \n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...   \n",
       "\n",
       "       char_count  word_count  word_density  punctuation_count  \\\n",
       "12896         268          52      5.056604                  8   \n",
       "13183         399          84      4.694118                 20   \n",
       "1496          525         104      5.000000                 19   \n",
       "5205          203          35      5.638889                 10   \n",
       "13366         295          51      5.673077                 22   \n",
       "\n",
       "       title_word_count  upper_case_word_count  Polarity  Subjectivity  \n",
       "12896                 2                      0  0.170455      0.490909  \n",
       "13183                 2                      1  0.101944      0.719537  \n",
       "1496                  2                      2  0.186538      0.458761  \n",
       "5205                  2                      0  0.625000      0.825000  \n",
       "13366                 2                      0  0.329613      0.510268  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20769998-4b21-4904-9008-79e9d912ab37",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3e36cb15-5585-4b8e-bcde-de82a1f281ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.26      0.38      1271\n",
      "           1       0.82      0.97      0.89      4390\n",
      "\n",
      "    accuracy                           0.81      5661\n",
      "   macro avg       0.75      0.61      0.63      5661\n",
      "weighted avg       0.79      0.81      0.77      5661\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>336</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152</td>\n",
       "      <td>4238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  336   935\n",
       "1  152  4238"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train, )\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10381c25-f36a-46a7-ad3f-839b1954205d",
   "metadata": {},
   "source": [
    "Lo hace un poquito mejor igual lo hace como el poto xdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c08fc4-ac7f-449c-a1f7-6e42a8d7a139",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "Adding Bag of Words based Features - 1-grams.\n",
    "\n",
    "\n",
    "Es la estructura ams simple de representacion matematica de texto no estructurado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12595e1b-da90-4f40-b6b6-69926b3b6f97",
   "metadata": {},
   "source": [
    "#### Text Pre-processing and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d42be9-7974-4cda-9f4d-afdd7e220291",
   "metadata": {},
   "source": [
    "La idea es ver si con feature engineering podemos mejorar. \n",
    "\n",
    "We want to extract some specific features based on standard NLP feature engineering models like the classic Bag of Words model. For this we need to clean and pre-process our text data. We will build a simple text pre-processor here since the main intent is to look at feature engineering strategies.\n",
    "\n",
    "We will focus on:\n",
    "\n",
    "* Text Lowercasing\n",
    "* Removal of contractions\n",
    "* Removing unnecessary characters, numbers and symbols\n",
    "* Stemming\n",
    "* Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b70ca4f-fc87-4f0a-a05f-74b8bc3ef230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk ## pre-processing\n",
    "import contractions ## Elimina acortadas\n",
    "import re ## remueve cosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "57433613-e0a2-4f15-8162-640cd624d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # expand contractions\n",
    "    document = contractions.fix(document)\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a2e8032e-b464-4fb7-aff9-21fd896ffd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Clean Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12896</th>\n",
       "      <td>Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....</td>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>soooo soft thi delight soft fluffi sweater might bought store petit size white wa pretti good weight not light heavi comfort would fun layer variou outfit not seem would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...</td>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "      <td>eye thi but dind get final visit store petit thi dress wa cours snag tri love color mean awesom fabric also veri soft but cut wa huh noth go rave think would nice casual day but often wear jogger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...</td>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "      <td>want like thi want like thi top badli badli fact first size not fit order two size make sure xl l none work realli want like thi top onlin photo make cloth look flatter shirt not least shirt onlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>beauti blous bought thi daughter law birthday beauti feminin design well made nice fabric wear thi work lunch even veri versatil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...</td>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "      <td>boxi larg boxi unflatt larg curvi pound thi top size swallow no shape materi not feel great either would not even purchas sale graphic tee much nicer stick splendid sundri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                        Review  \\\n",
       "12896  Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....   \n",
       "13183  Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...   \n",
       "1496   I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...   \n",
       "5205   Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...   \n",
       "13366  Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...   \n",
       "\n",
       "       char_count  word_count  word_density  punctuation_count  \\\n",
       "12896         268          52      5.056604                  8   \n",
       "13183         399          84      4.694118                 20   \n",
       "1496          525         104      5.000000                 19   \n",
       "5205          203          35      5.638889                 10   \n",
       "13366         295          51      5.673077                 22   \n",
       "\n",
       "       title_word_count  upper_case_word_count  Polarity  Subjectivity  \\\n",
       "12896                 2                      0  0.170455      0.490909   \n",
       "13183                 2                      1  0.101944      0.719537   \n",
       "1496                  2                      2  0.186538      0.458761   \n",
       "5205                  2                      0  0.625000      0.825000   \n",
       "13366                 2                      0  0.329613      0.510268   \n",
       "\n",
       "                                                                                                                                                                                                  Clean Review  \n",
       "12896                                soooo soft thi delight soft fluffi sweater might bought store petit size white wa pretti good weight not light heavi comfort would fun layer variou outfit not seem would  \n",
       "13183  eye thi but dind get final visit store petit thi dress wa cours snag tri love color mean awesom fabric also veri soft but cut wa huh noth go rave think would nice casual day but often wear jogger ...  \n",
       "1496   want like thi want like thi top badli badli fact first size not fit order two size make sure xl l none work realli want like thi top onlin photo make cloth look flatter shirt not least shirt onlin...  \n",
       "5205                                                                          beauti blous bought thi daughter law birthday beauti feminin design well made nice fabric wear thi work lunch even veri versatil  \n",
       "13366                              boxi larg boxi unflatt larg curvi pound thi top size swallow no shape materi not feel great either would not even purchas sale graphic tee much nicer stick splendid sundri  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Clean Review'] = stp(X_train['Review'].values)\n",
    "X_test['Clean Review'] = stp(X_test['Review'].values)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f08a5480-b358-48c3-acd7-a7d1546e9c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0         268          52      5.056604                  8                 2   \n",
       "1         399          84      4.694118                 20                 2   \n",
       "2         525         104      5.000000                 19                 2   \n",
       "3         203          35      5.638889                 10                 2   \n",
       "4         295          51      5.673077                 22                 2   \n",
       "\n",
       "   upper_case_word_count  Polarity  Subjectivity  \n",
       "0                      0  0.170455      0.490909  \n",
       "1                      1  0.101944      0.719537  \n",
       "2                      2  0.186538      0.458761  \n",
       "3                      0  0.625000      0.825000  \n",
       "4                      0  0.329613      0.510268  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_metadata = X_train.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "X_test_metadata = X_test.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "\n",
    "X_train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6e4d54f8-f913-4893-9124-c4baac321d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandidon</th>\n",
       "      <th>aaaaannnnnnd</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaahmaz</th>\n",
       "      <th>aaah</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbi</th>\n",
       "      <th>abck</th>\n",
       "      <th>...</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8554 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaaandidon  aaaaannnnnnd  aaaah  aaaahmaz  aaah  ab  abbey  abbi  \\\n",
       "0   0            0             0      0         0     0   0      0     0   \n",
       "1   0            0             0      0         0     0   0      0     0   \n",
       "2   0            0             0      0         0     0   0      0     0   \n",
       "3   0            0             0      0         0     0   0      0     0   \n",
       "4   0            0             0      0         0     0   0      0     0   \n",
       "\n",
       "   abck  ...  zing  zip  zipper  zipperi  zippi  zone  zooland  zoom  zowi  \\\n",
       "0     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "1     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "2     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "3     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "4     0  ...     0    0       0        0      0     0        0     0     0   \n",
       "\n",
       "   zuma  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 8554 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\n",
    "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec321cf0-f6a6-425b-a6c4-6ae2dcd2fa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandidon</th>\n",
       "      <th>...</th>\n",
       "      <th>zing</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>52</td>\n",
       "      <td>5.056604</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>399</td>\n",
       "      <td>84</td>\n",
       "      <td>4.694118</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.719537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>104</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186538</td>\n",
       "      <td>0.458761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>51</td>\n",
       "      <td>5.673077</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.510268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0         268          52      5.056604                  8                 2   \n",
       "1         399          84      4.694118                 20                 2   \n",
       "2         525         104      5.000000                 19                 2   \n",
       "3         203          35      5.638889                 10                 2   \n",
       "4         295          51      5.673077                 22                 2   \n",
       "\n",
       "   upper_case_word_count  Polarity  Subjectivity  aa  aaaaandidon  ...  zing  \\\n",
       "0                      0  0.170455      0.490909   0            0  ...     0   \n",
       "1                      1  0.101944      0.719537   0            0  ...     0   \n",
       "2                      2  0.186538      0.458761   0            0  ...     0   \n",
       "3                      0  0.625000      0.825000   0            0  ...     0   \n",
       "4                      0  0.329613      0.510268   0            0  ...     0   \n",
       "\n",
       "   zip  zipper  zipperi  zippi  zone  zooland  zoom  zowi  zuma  \n",
       "0    0       0        0      0     0        0     0     0     0  \n",
       "1    0       0        0      0     0        0     0     0     0  \n",
       "2    0       0        0      0     0        0     0     0     0  \n",
       "3    0       0        0      0     0        0     0     0     0  \n",
       "4    0       0        0      0     0        0     0     0     0  \n",
       "\n",
       "[5 rows x 8562 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233843ce-81e1-46bc-b1ea-953227d2b7d8",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61f94734-f462-46c0-9dd3-1678e48e494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      1271\n",
      "           1       0.92      0.93      0.93      4390\n",
      "\n",
      "    accuracy                           0.88      5661\n",
      "   macro avg       0.84      0.82      0.83      5661\n",
      "weighted avg       0.88      0.88      0.88      5661\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>895</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286</td>\n",
       "      <td>4104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0  895   376\n",
       "1  286  4104"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_comb, y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9a2ff-3f4c-42ae-9a16-eaeb25bb2794",
   "metadata": {},
   "source": [
    "Mejoro harto en comparacion a los demas, supongo que hacer un n-gram mejorara aun mas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
